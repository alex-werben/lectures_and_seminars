{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad63700d-0d95-4bfa-93ea-d3ec474abe25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(60000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f756b35-d1dd-47f8-b500-9b79d21e39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49f5e001-1d1b-4019-9429-367a9a759f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import ollama\n",
    "import torch\n",
    "import datasets\n",
    "import transformers\n",
    "from IPython.display import clear_output\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ed76a69-1979-41c7-b8b0-530b3ac92f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# понадобится для оценки модели\n",
    "# pip install human-eval==1.0.3\n",
    "# pip install ollama==0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6f1ed62-4f16-4268-ac21-28ddd9f4d194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13.5 (main, Jun 11 2025, 15:36:57) [Clang 17.0.0 (clang-1700.0.13.3)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c94e40b-0fda-4eae-a5d0-21f40a85087f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 2.7.1\n",
      "datasets 3.6.0\n",
      "transformers 4.46.0\n"
     ]
    }
   ],
   "source": [
    "print('torch', torch.__version__)\n",
    "print('datasets', datasets.__version__)\n",
    "print('transformers', transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55cc252-f6d5-4a40-9e03-0eb5c092c87f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Семинар 4, Часть 2: AI Coding Assistants в Enterprise\n",
    "## От автодополнения до автономных агентов-разработчиков\n",
    "\n",
    "Сегодня мы погрузимся в мир AI-ассистентов для разработки. Эти инструменты эволюционировали от простых подсказчиков до мощных систем, способных понимать весь проект и выполнять сложные задачи автономно. \n",
    "\n",
    "На этом семинаре мы:\n",
    "1.  Рассмотрим ключевых игроков на рынке AI-ассистентов.\n",
    "2.  Разберем 5 уровней \"интеллекта\" этих инструментов.\n",
    "3.  Заглянем \"под капот\" и разберем технологии, которые делают их возможными: от Fill-in-the-Middle до RAG и агентных фреймворков.\n",
    "4.  Напишем код, иллюстрирующий эти ключевые концепции.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ab13c1-c63d-4852-92c0-c91439cb64b6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Обзор существующих решений\n",
    "\n",
    "Рынок AI-ассистентов для разработки быстро растет. Рассмотрим несколько популярных и интересных примеров, которые представляют разные подходы к помощи разработчику.\n",
    "\n",
    "| Инструмент | Ключевая особенность | Модель использования | Ссылка |\n",
    "|---|---|---|---|\n",
    "| **GitHub Copilot** | Глубокая интеграция с экосистемой GitHub и VS Code. Стандарт индустрии. | Плагин в IDE | [Website](https://github.com/features/copilot) / [GIT](https://github.com/microsoft/vscode-copilot-chat)|\n",
    "| **Cursor** | Форк VS Code, \"AI-first\" IDE с нативным чатом и анализом всего репозитория. | Stand-alone IDE | [Website](https://cursor.sh/) |\n",
    "| **Continue** | Open-source и кастомизируемая платформа. Позволяет подключать свои модели (в т.ч. локальные). | Плагин в IDE | [GitHub](https://github.com/continuedev/continue) / [GIT](https://github.com/continuedev/continue)|\n",
    "| **Void** | Privacy-focused альтернатива Cursor с поддержкой локальных LLM. | Stand-alone IDE | [GitHub](https://github.com/voideditor/void) / [GIT](https://github.com/voideditor/void)|\n",
    "| **Cline** | Автономный агент для VS Code с доступом к терминалу для выполнения задач. | Плагин в IDE | [GitHub](https://github.com/cline/cline) / [GIT](https://github.com/cline/cline)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a283ba9e-2fe3-4c57-b920-992e317d6e6d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Пять уровней \"помощи\" AI-ассистента\n",
    "\n",
    "Чтобы лучше понять эволюцию и возможности этих инструментов, можно выделить 5 условных уровней их \"интеллекта\" и автономности:\n",
    "\n",
    "1. **Прямая генерация кода (Autocomplete)**\n",
    "   *Самая известная функция: вы начинаете писать код, и ассистент предлагает завершение строки или целый блок кода. Это быстро и интуитивно.*\n",
    "\n",
    "2. **Интерактивный чат и генерация по запросу**\n",
    "   *Вы можете \"поговорить\" с ассистентом: выделить код и спросить: \"Объясни, что здесь происходит\", \"Найди ошибку\" или попросить сгенерировать функцию по описанию.*\n",
    "\n",
    "3. **Автоматический рефакторинг и \"умные\" правки**\n",
    "   *Ассистент может предложить улучшенную версию кода (например, более читаемую или производительную). Изменения отображаются в виде diff-сравнения.*\n",
    "\n",
    "4. **Понимание всего проекта (Full Codebase Awareness)**\n",
    "   *Ассистент дает ответы, учитывая весь ваш проект, а не только открытые файлы. Он знает о ваших кастомных классах и архитектуре.*\n",
    "\n",
    "5. **\"Агенты\" и автономные задачи (Code Agents)**\n",
    "   *Вы ставите высокоуровневую задачу: \"Добавь аутентификацию через GitHub\". Агент сам составляет план, находит и редактирует нужные файлы, пишет код в нескольких местах и даже может запустить тесты для проверки.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf06b95-11c7-4518-b9a6-d0780cd4fe2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96f8159e-8add-4ff1-8484-d5cfbec2afe2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Как это работает под капотом\n",
    "\n",
    "### Уровень 1: Инлайновые подсказки и Fill-in-the-Middle\n",
    "**Как это работает?** \n",
    "\n",
    "- **Триггер**: Срабатывает автоматически после паузы во время набора текста.\n",
    "- **Сбор контекста**: Система собирает очень ограниченный, но релевантный контекст: текст до и после курсора в текущем файле. Скорость здесь — главный приоритет.\n",
    "- **Формирование промпта (Fill-in-the-Middle)**: Вместо простого дополнения текста, современные модели используют технику FIM. Они получают на вход начало файла (префикс) и конец файла (суффикс), а их задача — сгенерировать недостающую середину. Это позволяет им лучше учитывать контекст с обеих сторон от курсора.\n",
    "- **Запрос к модели**: Запрос отправляется к легковесной, быстрой LLM, оптимизированной для генерации кода (например, StarCoder, Code Llama, DeepSeek Coder).\n",
    "- **Отображение**: Полученный ответ мгновенно отображается в редакторе как неактивный текст.\n",
    "\n",
    "\n",
    "\n",
    "### Задача Fill-in-the-Middle (FIM)\n",
    "\n",
    "- **Цель:** Дать модели фрагменты кода — префикс (prefix) и суффикс (suffix) — а модель должна сгенерировать «средний» пропущенный код (middle), так чтобы весь код $$prefix + middle + suffix$$ был синтаксически корректным и семантически релевантным.\n",
    "- Такой подход позволяет лучше учитывать контекст с обеих сторон от места вставки по сравнению с классическим left-to-right (L2R) автодополнением.\n",
    "\n",
    "### Обучение модели: подготовка данных и трансформация\n",
    "\n",
    "- Исходный документ кода случайным образом делится на 3 части:\n",
    "  - Префикс (prefix) — начало документа или кода перед вставкой\n",
    "  - Средняя часть (middle) — код, который модель должна сгенерировать\n",
    "  - Суффикс (suffix) — код после вставки\n",
    "- Создается трансформированный обучающий пример вида:\n",
    "\n",
    "$$\n",
    "\\text{input} = [\\text{prefix}], [\\text{suffix}] \\quad\\rightarrow\\quad \\text{output} = [\\text{middle}]\n",
    "$$\n",
    "\n",
    "- Специальные токены и разделители обычно выделяют границы частей (например, `[PRE]`, `[SUF]`, `[MID]`).\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"docs/fitm_1.png\" alt=\"alt text\" style=\"width:400px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "### Метрики качества генерации\n",
    "\n",
    "- **Negative Log-Likelihood (NLL)** – основная метрика, оценивающая вероятность сгенерированной модели последовательности среднего фрагмента.\n",
    "- **Доля синтаксически корректных сгенерированных фрагментов (Syntax Validity Rate)**\n",
    "- **Точное совпадение (Exact Match, EM)** – процент сгенерированных средних частей, полностью совпадающих с целевыми.\n",
    "- **Качество интеграции (fluency, coherence)** – субъективная или автоматическая оценка качества стыковки с префиксом и суффиксом.\n",
    "\n",
    "\n",
    "Важно проводить оценку не только по общим метрикам, но и по тому, насколько хорошо модели восстанавливают синтаксические структуры на уровне AST (Abstract Syntax Tree).\n",
    "\n",
    "### Оценка по Abstract Syntax Tree:\n",
    "\n",
    "- **В эксперименте** участки кода маскируются, модель должна \"вставить\" пропущенное.  \n",
    "- Коды (реальный и сгенерированный) разбираются в AST, и сравнивают, какие синтаксические элементы (узлы дерева — Class Definition, If Statement, Assignment и др.) модель верно восстанавливает.\n",
    "- Для разных подходов обучения строятся сравнения — насколько точнее работают FIM-модели в восстановлении конкретных конструкций.\n",
    "\n",
    "### Интерпретация результата радар-графика:\n",
    "\n",
    "- Ось соответствует определённому типу AST-узла (см. подписи).\n",
    "- Радиус — прирост точности воспроизведения по сравнению с базой.\n",
    "- Линии разных моделей отражают, где и какие типы кода восстанавливаются лучше (например, Call Expression, Dotted Name, Parameters).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"docs/fitm_2.png\" alt=\"alt text\" style=\"width:400px;\">\n",
    "</div>\n",
    "\n",
    "Статьи на тему\n",
    "- [Structure-Aware Fill-in-the-Middle Pretraining for\n",
    "Code](https://arxiv.org/pdf/2506.00204)\n",
    "- [Improving FIM Code Completions via Context & Curriculum\n",
    "Based Learning](https://arxiv.org/pdf/2412.16589v1)\n",
    "\n",
    "Эталонные датасеты для оценки\n",
    "- Single-Line Infilling Benchmark — задачи на заполнение одной строки кода между контекстом.\n",
    "- CrossCodeEval — более сложный датасет с многопоточечными вызовами, зависимостями и распределением кода по файлам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a37e0298-d0c0-4eb4-ac6c-2beeb5f39e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем обученную модель fitm на практике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dea5b9e8-fbcd-49ac-9159-4798054d36d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден и используется графический процессор Apple (MPS).\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Найден и используется графический процессор Apple (MPS).\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Найдена и используется видеокарта NVIDIA (CUDA).\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU не найден, используется CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e82df4-b6b8-4d19-aa10-6ce74885c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigcode/starcoderbase-1b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"bigcode/starcoderbase-1b\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "581f94d6-b2a3-43ac-a12e-31b3a7c41508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определение префикса и суффикса\n",
    "prefix = \"def get_weather(city):\\n    # get weather from api\"\n",
    "suffix = \"\\n    return temperature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceb1e039-7deb-40da-ab8c-80a4ed09f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# формирование FIM-промпта\n",
    "# используются специальные токены для FIM\n",
    "prompt = f\"<fim_prefix>{prefix}<fim_suffix>{suffix}<fim_middle>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05a32ef8-2b55-4dd0-bd0a-57d1af47784b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Сформированный промпт для FIM модели ---\n",
      "<fim_prefix>def get_weather(city):\\n    # get weather from api<fim_suffix>\\n    return temperature<fim_middle>\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Сформированный промпт для FIM модели ---\")\n",
    "print(prompt.replace('\\n', '\\\\n'))\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19ae33b3-e55c-4e84-a619-87c1f940481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизация и отправка на устройство\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1754907c-7da3-4660-a7ee-f7fb5ccd4ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерация с параметрами сэмплирования\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_p=0.95,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.convert_tokens_to_ids([\"<file_separator>\"])[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac3bc743-3fc5-48d4-9160-bb0a74537145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# декодирование и очистка результата\n",
    "# убираем входной промпт из сгенерированного вывода\n",
    "new_tokens = outputs[0][len(inputs[\"input_ids\"][0]):]\n",
    "generated_code = tokenizer.decode(new_tokens, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4563bf27-34c1-45ba-b499-ebdc3eab3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# очищаем специальные токены, которые могут появиться в выводе\n",
    "middle_part = generated_code.replace(\"<|endoftext|>\", \"\").replace(\"<file_separator>\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "704e5144-d6cc-48e1-bf07-1cae5d802e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Сгенерированный код (вставка) ---\n",
      "weather = requests.get(f'https://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_KEY}')\n",
      "    return weather.json()\n",
      "\n",
      "def get_temperature(city):\n",
      "    # get temperature from api\n",
      "    weather = requests.get\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Сгенерированный код (вставка) ---\")\n",
    "print(middle_part)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbf4092a-ff9e-42db-8618-697c48cdb9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Итоговый полный код ---\n",
      "def get_weather(city):\n",
      "    # get weather from api\n",
      "    weather = requests.get(f'https://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_KEY}')\n",
      "    return weather.json()\n",
      "\n",
      "def get_temperature(city):\n",
      "    # get temperature from api\n",
      "    weather = requests.get\n",
      "    return temperature\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Итоговый полный код ---\")\n",
    "final_code = f\"{prefix}\\n    {middle_part}{suffix}\"\n",
    "print(final_code)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d05f58-df72-4407-afa0-806e4848157c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f74ff86e-12c1-47b1-b381-9a11f3e54fd2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Уровень 2: Интерактивный чат и специализированные модели\n",
    "**Как это работает?**\n",
    "\n",
    "- **Триггер**: Явное действие пользователя — отправка сообщения в чате.\n",
    "- **Сбор контекста**: Система собирает выделенный пользователем фрагмент кода, его вопрос на естественном языке и, возможно, содержимое всего активного файла.\n",
    "- **Формирование промпта**: Создается инструктивный промпт: `\"User has selected the following code: ... He asked the following question: ... Analyze and answer.\"`\n",
    "- **Запрос к модели**: Запрос отправляется к более мощной, \"разговорной\" LLM (например, GPT-4, Claude 3, Llama 3). Для задач, связанных с кодом, предпочтительны модели, дообученные на коде, так как они лучше понимают синтаксис и паттерны.\n",
    "- **Отображение**: Ответ выводится в окне чата.\n",
    "\n",
    "#### Почему специализированные на коде модели лучше?\n",
    "Модели, специально обученные на огромных массивах исходного кода (например, `CodeLlama`, `DeepSeek-Coder`), обладают глубоким \"пониманием\" синтаксических структур, идиом программирования и распространенных алгоритмов. Они с меньшей вероятностью допустят синтаксические ошибки и предложат более релевантные и эффективные решения, чем модели общего назначения такой же размерности.\n",
    "\n",
    "\n",
    "### Методология обучения и специализации LLM для генерации кода\n",
    "#### 1.1. Предобучение (Pre-training): Создание Фундаментальной Модели\n",
    "На этом этапе закладывается основа модели — ее способность к обобщенному представлению синтаксических и семантических конструкций кода.\n",
    "\n",
    "*   **Цель:** Обучить модель улавливать статистические закономерности и низкоуровневые паттерны в коде посредством самообучения (unsupervised learning).\n",
    "*   **Данные:** Крупномасштабные текстовые корпусы, состоящие из триллионов токенов исходного кода из публичных репозиториев (например, GitHub), технической документации и специализированных баз данных.\n",
    "*   **Процесс:**\n",
    "    *   **Causal Language Modeling (CLM):** Основная задача — предсказание следующего токена в последовательности. Это заставляет модель изучать грамматические правила, синтаксические структуры и идиоматические конструкции языка программирования.\n",
    "    *   **Code-Aware Tokenization:** Применяются специализированные токенизаторы, которые сохраняют целостность лексем кода (имена переменных, функций, операторы), что критически важно для семантической корректности.\n",
    "*   **Результат:** Фундаментальная модель (Foundation Model) с обобщенным представлением о синтаксисе и структуре множества языков программирования, но без специализации для выполнения конкретных инструкций.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"docs/code_llm.png\" alt=\"alt text\" style=\"width:400px;\">\n",
    "</div>\n",
    "\n",
    "#### 1.2. Специализированное дообучение (Fine-Tuning): адаптация для конкретных задач\n",
    "На этом этапе фундаментальная модель адаптируется для выполнения узкоспециализированных задач, востребованных в разработке ПО.\n",
    "\n",
    "*   **Цель:** Повысить производительность модели на конкретных \"downstream\" задачах, таких как генерация кода по текстовому описанию, автодополнение, отладка и рефакторинг.\n",
    "*   **Данные:** Курируемые, высококачественные наборы данных, часто в формате \"инструкция-ответ\". Используются как синтетические данные, так и задачи из отраслевых бенчмарков (HumanEval, MBPP и др.).\n",
    "*   **Ключевые техники:**\n",
    "    *   **Supervised Fine-Tuning (SFT):** Модель обучается на размеченных парах \"запрос-эталонный код\". Это позволяет ей \"выровнять\" свои способности с ожиданиями пользователя и научиться генерировать код, соответствующий поставленной задаче.\n",
    "    *   **Instruction Tuning:** Процесс дообучения, направленный на улучшение способности модели следовать сложным инструкциям на естественном языке, включая многошаговые рассуждения и учет ограничений.\n",
    "*   **Результат:** Специализированная модель, демонстрирующая высокую точность в целевых задачах, генерирующая более идиоматичный и контекстуально релевантный код.\n",
    "\n",
    "### 2. Как оценивать такие модели\n",
    "\n",
    "#### 2.1. Бенчмарки\n",
    "\n",
    "| Бенчмарк | Назначение и фокус | Структура задач | Основная метрика |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **HumanEval** | Оценка способности к решению алгоритмических задач и генерации функционально корректного кода по текстовому описанию. | 164 задачи на Python, требующие написания тела функции на основе докстринга и сигнатуры. | `pass@k` |\n",
    "| **MBPP** | Измерение производительности на базовых задачах программирования. | задачи на Python, менее сложных, чем в HumanEval, с фокусом на стандартные операции. | `pass@k` |\n",
    "| **CodeXGLUE** | Комплексная оценка широкого спектра задач, связанных с кодом: от генерации и перевода до поиска уязвимостей. | Набор из 14 датасетов, покрывающий 10 различных задач в области Code Intelligence. | `CodeBLEU`, `Accuracy` |\n",
    "\n",
    "#### 2.2. Интерпретация ключевых метрик\n",
    "\n",
    "*   **`pass@k`**:\n",
    "    *   **Определение:** Вероятность того, что хотя бы один из `k` сгенерированных моделью кандидатов успешно проходит все предоставленные юнит-тесты.\n",
    "    *   **Значение:** Прямая и объективная оценка функциональной корректности генерируемого кода. `pass@1` является наиболее строгим вариантом, оценивающим первую же попытку модели.\n",
    "\n",
    "*   **`CodeBLEU`**:\n",
    "    *   **Определение:** Адаптированная для кода версия метрики BLEU. Сравнивает сгенерированный код с эталонным, анализируя совпадения n-граммов, синтаксическую структуру (через Abstract Syntax Tree, AST) и поток данных (data-flow).\n",
    "    *   **Значение:** Оценивает не только лексическое совпадение, но и структурное и семантическое качество кода, приближаясь к оценке, которую дал бы человек-эксперт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f08da9c-8a3f-4b67-84f6-ff2cda5dd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценим работу модели qwen2.5-coder\n",
    "# подробнее о модели вот тут https://ollama.com/library/qwen2.5-coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "438ca091-7d2b-4ee4-8b21-403d9b1cb878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# карточка датасета для оценки (вариант 1)\n",
    "# https://huggingface.co/datasets/openai/openai_humaneval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb556191-22e3-45df-999c-c412580c8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# мы будем проверять на датасете попроще: MBPP (вариант 2)\n",
    "# запустим оценку заранее написанным скриптом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7ff44c68-bb77-4b58-abf8-6d3377986325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Задача 11: успешно\n",
      "✅ Задача 12: успешно\n",
      "✅ Задача 14: успешно\n",
      "✅ Задача 16: успешно\n",
      "✅ Задача 17: успешно\n",
      "❌ Задача 18: ошибка\n",
      "✅ Задача 19: успешно\n",
      "❌ Задача 20: ошибка\n",
      "❌ Задача 56: ошибка\n",
      "✅ Задача 57: успешно\n",
      "✅ Задача 58: успешно\n",
      "✅ Задача 59: успешно\n",
      "✅ Задача 61: успешно\n",
      "✅ Задача 62: успешно\n",
      "❌ Задача 63: ошибка\n",
      "✅ Задача 64: успешно\n",
      "✅ Задача 65: успешно\n",
      "✅ Задача 66: успешно\n",
      "✅ Задача 67: успешно\n",
      "✅ Задача 68: успешно\n",
      "✅ Задача 69: успешно\n",
      "❌ Задача 70: ошибка\n",
      "✅ Задача 71: успешно\n",
      "❌ Задача 72: ошибка\n",
      "✅ Задача 74: успешно\n",
      "✅ Задача 75: успешно\n",
      "✅ Задача 77: успешно\n",
      "✅ Задача 79: успешно\n",
      "✅ Задача 80: успешно\n",
      "❌ Задача 82: ошибка\n",
      "❌ Задача 83: ошибка\n",
      "✅ Задача 84: успешно\n",
      "❌ Задача 85: ошибка\n",
      "✅ Задача 86: успешно\n",
      "❌ Задача 87: ошибка\n",
      "✅ Задача 88: успешно\n",
      "✅ Задача 89: успешно\n",
      "✅ Задача 90: успешно\n",
      "✅ Задача 91: успешно\n",
      "✅ Задача 92: успешно\n",
      "✅ Задача 93: успешно\n",
      "✅ Задача 94: успешно\n",
      "✅ Задача 95: успешно\n",
      "✅ Задача 96: успешно\n",
      "✅ Задача 97: успешно\n",
      "❌ Задача 98: ошибка\n",
      "✅ Задача 99: успешно\n",
      "✅ Задача 100: успешно\n",
      "✅ Задача 101: успешно\n",
      "✅ Задача 102: успешно\n",
      "✅ Задача 103: успешно\n",
      "❌ Задача 104: ошибка\n",
      "✅ Задача 105: успешно\n",
      "❌ Задача 106: ошибка\n",
      "✅ Задача 108: успешно\n",
      "✅ Задача 109: успешно\n",
      "❌ Задача 111: ошибка\n",
      "✅ Задача 113: успешно\n",
      "✅ Задача 115: успешно\n",
      "✅ Задача 116: успешно\n",
      "❌ Задача 117: ошибка\n",
      "✅ Задача 118: успешно\n",
      "✅ Задача 119: успешно\n",
      "❌ Задача 120: ошибка\n",
      "❌ Задача 123: ошибка\n",
      "❌ Задача 124: ошибка\n",
      "✅ Задача 125: успешно\n",
      "❌ Задача 126: ошибка\n",
      "✅ Задача 127: успешно\n",
      "✅ Задача 128: успешно\n",
      "✅ Задача 129: успешно\n",
      "✅ Задача 130: успешно\n",
      "✅ Задача 131: успешно\n",
      "✅ Задача 132: успешно\n",
      "✅ Задача 133: успешно\n",
      "✅ Задача 135: успешно\n",
      "❌ Задача 137: ошибка\n",
      "❌ Задача 138: ошибка\n",
      "❌ Задача 139: ошибка\n",
      "✅ Задача 140: успешно\n",
      "❌ Задача 141: ошибка\n",
      "✅ Задача 142: успешно\n",
      "❌ Задача 143: ошибка\n",
      "✅ Задача 145: успешно\n",
      "❌ Задача 160: ошибка\n",
      "✅ Задача 161: успешно\n",
      "✅ Задача 162: успешно\n",
      "❌ Задача 163: ошибка\n",
      "❌ Задача 164: ошибка\n",
      "✅ Задача 165: успешно\n",
      "✅ Задача 166: успешно\n",
      "✅ Задача 167: успешно\n",
      "✅ Задача 168: успешно\n",
      "✅ Задача 170: успешно\n",
      "✅ Задача 171: успешно\n",
      "✅ Задача 172: успешно\n",
      "✅ Задача 222: успешно\n",
      "❌ Задача 223: ошибка\n",
      "✅ Задача 224: успешно\n",
      "✅ Задача 226: успешно\n",
      "✅ Задача 227: успешно\n",
      "❌ Задача 228: ошибка\n",
      "❌ Задача 229: ошибка\n",
      "✅ Задача 230: успешно\n",
      "✅ Задача 232: успешно\n",
      "❌ Задача 233: ошибка\n",
      "✅ Задача 234: успешно\n",
      "❌ Задача 235: ошибка\n",
      "❌ Задача 237: ошибка\n",
      "✅ Задача 238: успешно\n",
      "✅ Задача 239: успешно\n",
      "❌ Задача 240: ошибка\n",
      "✅ Задача 242: успешно\n",
      "❌ Задача 244: ошибка\n",
      "✅ Задача 245: успешно\n",
      "❌ Задача 246: ошибка\n",
      "✅ Задача 247: успешно\n",
      "❌ Задача 248: ошибка\n",
      "❌ Задача 249: ошибка\n",
      "✅ Задача 250: успешно\n",
      "✅ Задача 251: успешно\n",
      "❌ Задача 252: ошибка\n",
      "✅ Задача 253: успешно\n",
      "❌ Задача 255: ошибка\n",
      "✅ Задача 256: успешно\n",
      "✅ Задача 257: успешно\n",
      "❌ Задача 259: ошибка\n",
      "❌ Задача 260: ошибка\n",
      "✅ Задача 261: успешно\n",
      "✅ Задача 262: успешно\n",
      "✅ Задача 264: успешно\n",
      "❌ Задача 265: ошибка\n",
      "✅ Задача 266: успешно\n",
      "✅ Задача 267: успешно\n",
      "✅ Задача 268: успешно\n",
      "✅ Задача 269: успешно\n",
      "✅ Задача 270: успешно\n",
      "✅ Задача 271: успешно\n",
      "✅ Задача 272: успешно\n",
      "✅ Задача 273: успешно\n",
      "✅ Задача 274: успешно\n",
      "❌ Задача 276: ошибка\n",
      "✅ Задача 277: успешно\n",
      "✅ Задача 278: успешно\n",
      "❌ Задача 279: ошибка\n",
      "✅ Задача 280: успешно\n",
      "✅ Задача 281: успешно\n",
      "✅ Задача 282: успешно\n",
      "✅ Задача 283: успешно\n",
      "✅ Задача 284: успешно\n",
      "✅ Задача 285: успешно\n",
      "❌ Задача 286: ошибка\n",
      "✅ Задача 287: успешно\n",
      "❌ Задача 290: ошибка\n",
      "❌ Задача 291: ошибка\n",
      "✅ Задача 292: успешно\n",
      "✅ Задача 293: успешно\n",
      "✅ Задача 294: успешно\n",
      "❌ Задача 295: ошибка\n",
      "✅ Задача 296: успешно\n",
      "✅ Задача 297: успешно\n",
      "❌ Задача 299: ошибка\n",
      "❌ Задача 300: ошибка\n",
      "❌ Задача 301: ошибка\n",
      "❌ Задача 304: ошибка\n",
      "❌ Задача 305: ошибка\n",
      "❌ Задача 306: ошибка\n",
      "❌ Задача 307: ошибка\n",
      "✅ Задача 308: успешно\n",
      "✅ Задача 309: успешно\n",
      "❌ Задача 310: ошибка\n",
      "❌ Задача 311: ошибка\n",
      "❌ Задача 312: ошибка\n",
      "✅ Задача 388: успешно\n",
      "✅ Задача 389: успешно\n",
      "❌ Задача 390: ошибка\n",
      "❌ Задача 391: ошибка\n",
      "❌ Задача 392: ошибка\n",
      "❌ Задача 393: ошибка\n",
      "✅ Задача 394: успешно\n",
      "✅ Задача 395: успешно\n",
      "❌ Задача 396: ошибка\n",
      "✅ Задача 397: успешно\n",
      "❌ Задача 398: ошибка\n",
      "✅ Задача 399: успешно\n",
      "❌ Задача 400: ошибка\n",
      "✅ Задача 401: успешно\n",
      "✅ Задача 404: успешно\n",
      "❌ Задача 405: ошибка\n",
      "✅ Задача 406: успешно\n",
      "❌ Задача 407: ошибка\n",
      "❌ Задача 408: ошибка\n",
      "✅ Задача 409: успешно\n",
      "✅ Задача 410: успешно\n",
      "✅ Задача 411: успешно\n",
      "✅ Задача 412: успешно\n",
      "✅ Задача 413: успешно\n",
      "✅ Задача 414: успешно\n",
      "❌ Задача 415: ошибка\n",
      "❌ Задача 417: ошибка\n",
      "✅ Задача 418: успешно\n",
      "✅ Задача 419: успешно\n",
      "✅ Задача 420: успешно\n",
      "❌ Задача 421: ошибка\n",
      "✅ Задача 422: успешно\n",
      "✅ Задача 424: успешно\n",
      "✅ Задача 425: успешно\n",
      "✅ Задача 426: успешно\n",
      "✅ Задача 427: успешно\n",
      "✅ Задача 428: успешно\n",
      "✅ Задача 429: успешно\n",
      "❌ Задача 430: ошибка\n",
      "❌ Задача 431: ошибка\n",
      "✅ Задача 432: успешно\n",
      "✅ Задача 433: успешно\n",
      "✅ Задача 434: успешно\n",
      "✅ Задача 435: успешно\n",
      "✅ Задача 436: успешно\n",
      "❌ Задача 437: ошибка\n",
      "❌ Задача 438: ошибка\n",
      "✅ Задача 439: успешно\n",
      "❌ Задача 440: ошибка\n",
      "✅ Задача 441: успешно\n",
      "❌ Задача 442: ошибка\n",
      "❌ Задача 443: ошибка\n",
      "❌ Задача 444: ошибка\n",
      "❌ Задача 445: ошибка\n",
      "❌ Задача 446: ошибка\n",
      "✅ Задача 447: успешно\n",
      "❌ Задача 448: ошибка\n",
      "✅ Задача 450: успешно\n",
      "✅ Задача 451: успешно\n",
      "❌ Задача 452: ошибка\n",
      "✅ Задача 453: успешно\n",
      "✅ Задача 454: успешно\n",
      "✅ Задача 455: успешно\n",
      "✅ Задача 456: успешно\n",
      "✅ Задача 457: успешно\n",
      "✅ Задача 458: успешно\n",
      "✅ Задача 459: успешно\n",
      "✅ Задача 460: успешно\n",
      "❌ Задача 461: ошибка\n",
      "❌ Задача 462: ошибка\n",
      "✅ Задача 463: успешно\n",
      "✅ Задача 464: успешно\n",
      "✅ Задача 465: успешно\n",
      "❌ Задача 468: ошибка\n",
      "✅ Задача 470: успешно\n",
      "✅ Задача 471: успешно\n",
      "✅ Задача 472: успешно\n",
      "❌ Задача 473: ошибка\n",
      "✅ Задача 474: успешно\n",
      "❌ Задача 475: ошибка\n",
      "✅ Задача 476: успешно\n",
      "✅ Задача 477: успешно\n",
      "✅ Задача 478: успешно\n",
      "✅ Задача 479: успешно\n",
      "\n",
      "--- Итоги ---\n",
      "Всего задач:              257\n",
      "Решено правильно:         168\n",
      "Точность:                 65.37%\n"
     ]
    }
   ],
   "source": [
    "%run src/run_benchmark_mbpp.py --limit -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b72adee-112f-4dd6-92f7-51a5ccd91833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e48dae3-a43a-4cfb-ad60-3a3d6cd1dc44",
   "metadata": {},
   "source": [
    "**Это очень хороший результат!** 👍\n",
    "\n",
    "Для модели такого размера, запущенной на обычном компьютере без специальных настроек, справиться с 2/3 задач — это круто.\n",
    "\n",
    "Конечно, её \"старшие братья\" (более крупные модели на 32B или 72B) показывают точность выше (до 90%), но это и ожидаемо. 🏆\n",
    "\n",
    "---\n",
    "\n",
    "### Главные плюсы модели\n",
    "\n",
    "*   **Понимает базу:** Отлично справляется с основами Python.\n",
    "*   **Заточена под код:** Модель специально обучали на триллионах строк кода, и это чувствуется. 💻\n",
    "*   **Есть куда расти:** Результат можно легко улучшить, если немного поиграться с настройками. 📈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65a137-96f4-41f0-a378-6c19d353dc80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5225063-3f51-46e0-82fb-7f0e69cbcb7d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Уровень 3: Автоматический рефакторинг и \"умные\" правки\n",
    "\n",
    "Этот уровень представляет собой качественный скачок от простого автодополнения кода к полноценному **интеллектуальному ассистенту**, который не просто предлагает следующий токен, а понимает семантику кода и проактивно предлагает улучшения. Это не «что написать дальше?», а «как написать это лучше?».\n",
    "\n",
    "Системы этого уровня способны выполнять сложный рефакторинг, оптимизировать производительность и исправлять логические ошибки, действуя как опытный напарник-программист.\n",
    "\n",
    "---\n",
    "\n",
    "### Как это работает: разбор механики\n",
    "\n",
    "В основе лежит комплексный, многоэтапный процесс, который превращает сырой код в проанализированную, понятную для модели структуру, и обратно.\n",
    "\n",
    "### 1. Многоуровневый анализ структуры кода\n",
    "\n",
    "Прежде чем вносить правки, система проводит глубокий анализ исходного кода, выходя далеко за рамки простого парсинга в синтаксическое дерево (AST). Она строит **семантическую модель** кодовой базы, которая включает:\n",
    "\n",
    "*   **Синтаксическое дерево (AST):** Базовое представление структуры кода, показывающее иерархию операторов и выражений. Это «скелет» программы.\n",
    "*   **Граф зависимостей:** Система строит карту связей между функциями, классами, переменными и модулями. Это позволяет понять, как изменение в одном месте (например, в функции `A`) повлияет на другое (на функцию `B`, которая вызывает `A`).\n",
    "*   **Контекстная информация:** Собираются все метаданные:\n",
    "    *   **Импорты:** Какие библиотеки и модули используются?\n",
    "    *   **Область видимости (Scope):** Какие переменные доступны в данном участке кода?\n",
    "    *   **Типы данных:** Явно или неявно определенные типы переменных и возвращаемых значений.\n",
    "*   **Анализ паттернов и узких мест:** Система ищет распространенные анти-паттерны (например, неэффективные циклы, дублирование кода) и потенциальные точки для оптимизации (например, ресурсоемкие операции, которые можно распараллелить или кэшировать).\n",
    "\n",
    "> **Цель этого этапа** — не просто «прочитать» код, а «понять» его на уровне архитектора, видя все взаимосвязи и потенциальные проблемы.\n",
    "\n",
    "### 2. Интеллектуальное формирование промпта\n",
    "\n",
    "Когда анализ завершен, система не отправляет в LLM весь файл с кодом. Она формирует **структурированный, обогащенный промпт**, который содержит всю собранную информацию в сжатом и понятном для модели виде.\n",
    "\n",
    "Такой промпт может включать:\n",
    "\n",
    "*   **Исходный код с аннотациями:** Критические участки кода помечаются специальными комментариями, указывающими на проблему (`// SLOW_PERFORMANCE`, `// CODE_DUPLICATION`).\n",
    "*   **Упрощенное AST-представление:** Вместо полного дерева передаются только ключевые узлы, относящиеся к задаче рефакторинга.\n",
    "*   **Контекст окружающего кода:** Краткое описание зависимостей, например: `Функция 'process_data' вызывается в 10 местах и работает с объектом типа 'User'`.\n",
    "*   **Специфичные инструкции:** Четкая задача для модели, например: `«Рефакторинг функции 'get_user_list'. Замени неэффективный цикл на list comprehension. Убедись, что сохраняется исходная логика фильтрации»`.\n",
    "\n",
    "> **Результат:** Модель получает не просто «стену текста», а техническое задание с полным контекстом, что на порядки повышает качество и релевантность генерации.\n",
    "\n",
    "\n",
    "### 3. 🧪 Верификация и самокоррекция\n",
    "\n",
    "Предложенное решение не сразу попадает к пользователю. Оно проходит через автоматизированный конвейер проверки:\n",
    "\n",
    "1.  **Компиляция / Интерпретация:** Система проверяет, что сгенерированный код синтаксически корректен и вообще запускается.\n",
    "2.  **Автоматическое тестирование:** Запускаются существующие юнит-тесты, относящиеся к измененному коду. В идеале, система может сама сгенерировать временные тесты для проверки краевых случаев.\n",
    "3.  **Обратная связь и обучение (Self-Correction):**\n",
    "    *   **Если тесты провалены ✅ ➡️ ❌:** Результат с информацией об ошибке отправляется обратно в мульти-агентную систему. `Reviewer Agent` получает сообщение: `«Тест 'test_empty_list' провален с ошибкой 'IndexError'»`.\n",
    "    *   **Reinforcement Learning:** Этот цикл обратной связи (генерация -> тест -> провал -> новая генерация) позволяет системе обучаться на своих ошибках, постепенно улучшая качество предложений.\n",
    "\n",
    "> **Итог:** Пользователь получает не просто сгенерированный код, а решение, которое уже прошло несколько этапов проверки, компиляции и тестирования, что значительно повышает его надежность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c83e7f4e-7751-4a55-98fd-2d6ba490b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import inspect\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "443467e8-548a-4f59-b358-faaceacc5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RefactoringContext:\n",
    "    \"\"\"Контекст для рефакторинга с метаданными\"\"\"\n",
    "    source_code: str\n",
    "    ast_tree: ast.AST\n",
    "    function_name: str\n",
    "    complexity_score: int\n",
    "    dependencies: List[str]\n",
    "    suggested_patterns: List[str]\n",
    "\n",
    "class AdvancedCodeAnalyzer:\n",
    "    \"\"\"Продвинутый анализатор кода для формирования промптов\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.complexity_threshold = 10\n",
    "    \n",
    "    def extract_code_metrics(self, source_code: str) -> Dict[str, Any]:\n",
    "        \"\"\"Извлекает метрики сложности кода\"\"\"\n",
    "        tree = ast.parse(source_code)\n",
    "        \n",
    "        metrics = {\n",
    "            'cyclomatic_complexity': self._calculate_complexity(tree),\n",
    "            'lines_of_code': len(source_code.split('\\n')),\n",
    "            'nested_loops': self._count_nested_loops(tree),\n",
    "            'function_calls': self._extract_function_calls(tree),\n",
    "            'variables': self._extract_variables(tree)\n",
    "        }\n",
    "        return metrics\n",
    "    \n",
    "    def _calculate_complexity(self, tree: ast.AST) -> int:\n",
    "        \"\"\"Упрощенная оценка цикломатической сложности\"\"\"\n",
    "        complexity = 1\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, (ast.If, ast.While, ast.For, ast.Try)):\n",
    "                complexity += 1\n",
    "        return complexity\n",
    "    \n",
    "    def _count_nested_loops(self, tree: ast.AST) -> int:\n",
    "        \"\"\"Подсчет вложенных циклов\"\"\"\n",
    "        max_depth = 0\n",
    "        current_depth = 0\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, (ast.For, ast.While)):\n",
    "                current_depth += 1\n",
    "                max_depth = max(max_depth, current_depth)\n",
    "            # Упрощенная логика - в реальности нужен более сложный обход\n",
    "        return max_depth\n",
    "    \n",
    "    def _extract_function_calls(self, tree: ast.AST) -> List[str]:\n",
    "        \"\"\"Извлекает вызовы функций\"\"\"\n",
    "        calls = []\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Call):\n",
    "                if isinstance(node.func, ast.Name):\n",
    "                    calls.append(node.func.id)\n",
    "        return calls\n",
    "    \n",
    "    def _extract_variables(self, tree: ast.AST) -> List[str]:\n",
    "        \"\"\"Извлекает имена переменных\"\"\"\n",
    "        variables = []\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Name) and isinstance(node.ctx, ast.Store):\n",
    "                variables.append(node.id)\n",
    "        return variables\n",
    "    \n",
    "    def create_semantic_ast_summary(self, tree: ast.AST) -> Dict[str, Any]:\n",
    "        \"\"\"Создает семантическое резюме AST для промпта\"\"\"\n",
    "        summary = {\n",
    "            'structure': 'function_definition',\n",
    "            'control_flow': [],\n",
    "            'data_operations': [],\n",
    "            'optimization_opportunities': []\n",
    "        }\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.For):\n",
    "                summary['control_flow'].append({\n",
    "                    'type': 'for_loop',\n",
    "                    'target': node.target.id if isinstance(node.target, ast.Name) else 'complex',\n",
    "                    'iter': node.iter.id if isinstance(node.iter, ast.Name) else 'expression'\n",
    "                })\n",
    "            elif isinstance(node, ast.If):\n",
    "                summary['control_flow'].append({\n",
    "                    'type': 'conditional',\n",
    "                    'test_type': type(node.test).__name__\n",
    "                })\n",
    "            elif isinstance(node, ast.Assign):\n",
    "                summary['data_operations'].append({\n",
    "                    'type': 'assignment',\n",
    "                    'targets': [t.id for t in node.targets if isinstance(t, ast.Name)]\n",
    "                })\n",
    "            elif isinstance(node, ast.Call) and isinstance(node.func, ast.Attribute):\n",
    "                if node.func.attr == 'append':\n",
    "                    summary['optimization_opportunities'].append('list_comprehension_candidate')\n",
    "        \n",
    "        return summary\n",
    "\n",
    "def create_advanced_refactoring_prompt(context: RefactoringContext) -> str:\n",
    "    \"\"\"Создает продвинутый промпт для рефакторинга\"\"\"\n",
    "    \n",
    "    analyzer = AdvancedCodeAnalyzer()\n",
    "    metrics = analyzer.extract_code_metrics(context.source_code)\n",
    "    semantic_summary = analyzer.create_semantic_ast_summary(context.ast_tree)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        # Code Refactoring Task\n",
    "        \n",
    "        ## Context\n",
    "        - **Function**: `{context.function_name}`\n",
    "        - **Complexity Score**: {context.complexity_score}/10\n",
    "        - **Current Issues**: {', '.join(context.suggested_patterns)}\n",
    "        \n",
    "        ## Source Code Analysis\n",
    "        \n",
    "        {context.source_code.strip()}\n",
    "        \n",
    "        \n",
    "        ## Code Metrics\n",
    "        - **Lines of Code**: {metrics['lines_of_code']}\n",
    "        - **Cyclomatic Complexity**: {metrics['cyclomatic_complexity']}\n",
    "        - **Nested Loops**: {metrics['nested_loops']}\n",
    "        - **Function Calls**: {', '.join(metrics['function_calls']) if metrics['function_calls'] else 'None'}\n",
    "        - **Variables**: {', '.join(metrics['variables'])}\n",
    "        \n",
    "        ## Semantic Structure Analysis\n",
    "        \n",
    "        {json.dumps(semantic_summary, indent=2)}\n",
    "        \n",
    "        \n",
    "        ## Refactoring Requirements\n",
    "        1. **Primary Goal**: Convert imperative loop to functional approach\n",
    "        2. **Performance**: Optimize for readability and efficiency\n",
    "        3. **Style**: Follow PEP 8 and Python idioms\n",
    "        4. **Constraints**: \n",
    "           - Preserve original functionality exactly\n",
    "           - Maintain type hints compatibility\n",
    "           - Keep function signature unchanged\n",
    "        \n",
    "        ## Expected Improvements\n",
    "        - Replace manual list building with list comprehension\n",
    "        - Eliminate unnecessary intermediate variables\n",
    "        - Improve code readability and maintainability\n",
    "        \n",
    "        ## Output Format\n",
    "        Please provide:\n",
    "        1. **Refactored code** with comments explaining changes\n",
    "        2. **Performance analysis** comparing old vs new approach\n",
    "        3. **Risk assessment** for potential edge cases\n",
    "        \n",
    "        Generate the refactored version:\n",
    "        \"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c1d84e0d-721c-4270-a73c-7e64cc248ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_refactor(items):\n",
    "    \"\"\"Фильтрует четные числа и возводит их в квадрат\"\"\"\n",
    "    new_list = []\n",
    "    for i in items:\n",
    "        if i % 2 == 0:\n",
    "            new_list.append(i * i)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f1efa39e-f38b-482f-a20d-1edb3f151cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем контекст рефакторинга\n",
    "source_code = inspect.getsource(code_to_refactor)\n",
    "tree = ast.parse(source_code)\n",
    "\n",
    "context = RefactoringContext(\n",
    "    source_code=source_code,\n",
    "    ast_tree=tree,\n",
    "    function_name='code_to_refactor',\n",
    "    complexity_score=3,\n",
    "    dependencies=['builtins'],\n",
    "    suggested_patterns=['list_comprehension_candidate', 'functional_approach']\n",
    ")\n",
    "\n",
    "# Генерируем улучшенный промпт\n",
    "advanced_prompt = create_advanced_refactoring_prompt(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6d345b25-b67c-4a84-a922-cb8dcb7c80d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== УЛУЧШЕННЫЙ ПРОМПТ ===\n",
      "\n",
      "        # Code Refactoring Task\n",
      "\n",
      "        ## Context\n",
      "        - **Function**: `code_to_refactor`\n",
      "        - **Complexity Score**: 3/10\n",
      "        - **Current Issues**: list_comprehension_candidate, functional_approach\n",
      "\n",
      "        ## Source Code Analysis\n",
      "\n",
      "        def code_to_refactor(items):\n",
      "    \"\"\"Фильтрует четные числа и возводит их в квадрат\"\"\"\n",
      "    new_list = []\n",
      "    for i in items:\n",
      "        if i % 2 == 0:\n",
      "            new_list.append(i * i)\n",
      "    return new_list\n",
      "\n",
      "\n",
      "        ## Code Metrics\n",
      "        - **Lines of Code**: 8\n",
      "        - **Cyclomatic Complexity**: 3\n",
      "        - **Nested Loops**: 1\n",
      "        - **Function Calls**: None\n",
      "        - **Variables**: new_list, i\n",
      "\n",
      "        ## Semantic Structure Analysis\n",
      "\n",
      "        {\n",
      "  \"structure\": \"function_definition\",\n",
      "  \"control_flow\": [\n",
      "    {\n",
      "      \"type\": \"for_loop\",\n",
      "      \"target\": \"i\",\n",
      "      \"iter\": \"items\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"conditional\",\n",
      "      \"test_type\": \"Compare\"\n",
      "    }\n",
      "  ],\n",
      "  \"data_operations\": [\n",
      "    {\n",
      "      \"type\": \"assignment\",\n",
      "      \"targets\": [\n",
      "        \"new_list\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"optimization_opportunities\": [\n",
      "    \"list_comprehension_candidate\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "        ## Refactoring Requirements\n",
      "        1. **Primary Goal**: Convert imperative loop to functional approach\n",
      "        2. **Performance**: Optimize for readability and efficiency\n",
      "        3. **Style**: Follow PEP 8 and Python idioms\n",
      "        4. **Constraints**: \n",
      "           - Preserve original functionality exactly\n",
      "           - Maintain type hints compatibility\n",
      "           - Keep function signature unchanged\n",
      "\n",
      "        ## Expected Improvements\n",
      "        - Replace manual list building with list comprehension\n",
      "        - Eliminate unnecessary intermediate variables\n",
      "        - Improve code readability and maintainability\n",
      "\n",
      "        ## Output Format\n",
      "        Please provide:\n",
      "        1. **Refactored code** with comments explaining changes\n",
      "        2. **Performance analysis** comparing old vs new approach\n",
      "        3. **Risk assessment** for potential edge cases\n",
      "\n",
      "        Generate the refactored version:\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(\"=== УЛУЧШЕННЫЙ ПРОМПТ ===\")\n",
    "print(advanced_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ef558453-1fde-4429-97c0-5ccd79996f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ОЖИДАЕМЫЙ РЕЗУЛЬТАТ ===\n",
      "\n",
      "def code_to_refactor(items):\n",
      "    \"\"\"Фильтрует четные числа и возводит их в квадрат\n",
      "\n",
      "    Refactored to use list comprehension for better performance and readability.\n",
      "    \"\"\"\n",
      "    return [i * i for i in items if i % 2 == 0]\n",
      "\n",
      "# Performance Analysis:\n",
      "# - Old: O(n) with explicit loop and list.append() calls\n",
      "# - New: O(n) with optimized list comprehension (faster in CPython)\n",
      "# - Memory: Reduced intermediate variable usage\n",
      "# - Readability: More Pythonic and concise\n",
      "\n",
      "# Risk Assessment: LOW\n",
      "# - Functionality preserved exactly\n",
      "# - No edge case changes\n",
      "# - Type compatibility maintained\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Пример ожидаемого ответа от LLM\n",
    "expected_refactored = \"\"\"\n",
    "def code_to_refactor(items):\n",
    "    \\\"\\\"\\\"Фильтрует четные числа и возводит их в квадрат\n",
    "    \n",
    "    Refactored to use list comprehension for better performance and readability.\n",
    "    \\\"\\\"\\\"\n",
    "    return [i * i for i in items if i % 2 == 0]\n",
    "\n",
    "# Performance Analysis:\n",
    "# - Old: O(n) with explicit loop and list.append() calls\n",
    "# - New: O(n) with optimized list comprehension (faster in CPython)\n",
    "# - Memory: Reduced intermediate variable usage\n",
    "# - Readability: More Pythonic and concise\n",
    "\n",
    "# Risk Assessment: LOW\n",
    "# - Functionality preserved exactly\n",
    "# - No edge case changes\n",
    "# - Type compatibility maintained\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n=== ОЖИДАЕМЫЙ РЕЗУЛЬТАТ ===\")\n",
    "print(expected_refactored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "abb01e05-37cd-41f1-890c-a9878851791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.Client().generate(model=\"qwen2.5-coder:14b\", prompt=advanced_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f9c808b6-f6a9-4b41-b24e-f5d0a11fecd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def code_to_refactor(items) -> list[int]:\n",
      "    \"\"\"Фильтрует четные числа и возводит их в квадрат\"\"\"\n",
      "    # Refactored using list comprehension to improve readability and efficiency\n",
      "    return [i * i for i in items if i % 2 == 0]\n",
      "```\n",
      "\n",
      "### Performance Analysis\n",
      "\n",
      "#### Old Approach:\n",
      "- **Time Complexity**: O(n)\n",
      "- **Space Complexity**: O(n) due to the creation of `new_list`.\n",
      "- **Execution Steps**:\n",
      "  - Iterates over each element in `items` once.\n",
      "  - Checks if the element is even.\n",
      "  - If even, appends its square to `new_list`.\n",
      "\n",
      "#### New Approach (List Comprehension):\n",
      "- **Time Complexity**: O(n)\n",
      "- **Space Complexity**: O(n) due to the creation of a new list.\n",
      "- **Execution Steps**:\n",
      "  - Iterates over each element in `items` once.\n",
      "  - Checks if the element is even and squares it in one expression.\n",
      "\n",
      "### Risk Assessment\n",
      "\n",
      "1. **Type Safety**: The function signature specifies that the input should be a list of integers (`list[int]`). List comprehension maintains this type safety, as it processes each element individually.\n",
      "\n",
      "2. **Edge Cases**:\n",
      "   - **Empty Input**: Both the original and refactored code handle an empty list gracefully by returning an empty list.\n",
      "   - **Non-Integer Input**: The function does not explicitly handle non-integer inputs. If `items` contains non-integers, the modulo operation (`i % 2`) will raise a `TypeError`. To mitigate this, you could add type checking or use a try-except block if the function is expected to handle mixed types.\n",
      "   - **Large Inputs**: Both versions have the same time and space complexity. However, list comprehension might offer slight performance improvements due to reduced overhead.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The refactored code using list comprehension improves readability and adheres to Python idioms while preserving the original functionality. The performance remains consistent with the old version, and there are no significant risks introduced by this change.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9b3eb-97f6-4ac0-9e68-12bda10e5a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73c990f7-b53a-4a6b-b47e-0ecf098e4897",
   "metadata": {},
   "source": [
    "## Уровень 4: Понимание всего проекта (Full Codebase Awareness)\n",
    "\n",
    "\n",
    "Это принципиально другой подход, основанный на **Retrieval-Augmented Generation (RAG)**.\n",
    "Переходим на самый высокий уровень интеллектуальных ассистентов. Здесь система перестает быть просто анализатором одного файла и становится **полноценным архитектором**, который \"знает\" весь ваш проект целиком. Она способна отвечать на вопросы, для которых контекст разбросан по десяткам файлов, находить неочевидные зависимости и предлагать глобальные рефакторинги.\n",
    "\n",
    "**Ключевая идея:** Вместо того чтобы пытаться \"засунуть\" весь проект в ограниченное окно LLM, мы используем умный поиск, чтобы дать модели только ту информацию, которая нужна для ответа здесь и сейчас.\n",
    "\n",
    "---\n",
    "\n",
    "## Как это работает: Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "В основе этого подхода лежит технология **RAG** — генерация, обогащенная поиском. Процесс состоит из двух фаз: индексации (один раз) и поиска (при каждом запросе).\n",
    "\n",
    "###  Фаза 1: Индексация проекта (происходит заранее, в фоне)\n",
    "\n",
    "1.  **📚 Сканирование и Чанкинг:** Ассистент сканирует все файлы в проекте. Он не просто читает текст, а использует **семантический чанкинг**, разбивая код на логические блоки: функции, классы, методы. *(Подробнее о методах чанкинга — ниже)*.\n",
    "\n",
    "2.  **🧠 Создание Эмбеддингов:** Каждый такой блок (чанк) пропускается через специальную модель-эмбеддер, которая превращает его в **вектор** — числовое представление семантики кода. В этом векторе закодирована информация о том, *что* делает код, а не просто из каких символов он состоит.\n",
    "\n",
    "3.  **💾 Сохранение в Векторную Базу:** Все полученные векторы (эмбеддинги) вместе с исходным кодом сохраняются в локальную векторную базу данных (например, `FAISS`, `ChromaDB`). Эта база данных оптимизирована для сверхбыстрого поиска векторов по \"смысловой близости\".\n",
    "\n",
    "### Фаза 2: Работа с запросом (происходит в реальном времени)\n",
    "\n",
    "4.  **❓ Запрос пользователя:** Вы задаете вопрос или выделяете код, например: *\"Где используется функция `getUserPermissions` и как она обрабатывает гостевых пользователей?\"*\n",
    "\n",
    "5.  **🔍 Векторный поиск:** Система превращает ваш текстовый запрос в такой же вектор-эмбеддинг и ищет в базе данных наиболее близкие по смыслу векторы кода. Результатом будут те самые чанки (функции, классы) из вашего проекта, которые наиболее релевантны вопросу.\n",
    "\n",
    "6.  **✨ Обогащение промпта:** Найденные фрагменты кода добавляются в промпт для основной LLM в качестве дополнительного контекста. Финальный промпт для модели выглядит примерно так:\n",
    "\n",
    "> **Системный промпт:** \"Ты — эксперт-помощник по программированию. Ответь на вопрос пользователя, используя предоставленный контекст из его кодовой базы.\"\n",
    "> **Контекст (найденные чанки):**\n",
    "> ```python\n",
    "> # file: services/permissions.py\n",
    "> def getUserPermissions(user_id):\n",
    ">   # ... (код функции)\n",
    "> ```\n",
    "> ```python\n",
    "> # file: controllers/api.py\n",
    "> permissions = getUserPermissions(current_user.id)\n",
    "> if not permissions:\n",
    ">   # ... (обработка гостя)\n",
    "> ```\n",
    "> **Вопрос пользователя:** \"Где используется функция `getUserPermissions` и как она обрабатывает гостевых пользователей?\"\n",
    "\n",
    "**Результат:** LLM получает всю необходимую информацию для точного и контекстуально-верного ответа, даже если нужный код разбросан по разным файлам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c55c20-d643-45a5-b998-99f049cdc397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edd549fe-63f4-4c21-94d7-ea4446fca27d",
   "metadata": {},
   "source": [
    "\n",
    "## Модели эмбеддингов для кода\n",
    "\n",
    "Ключ к успеху RAG — это качество эмбеддингов. Модели, которые переводят код в векторы, — это настоящее произведение искусства.\n",
    "\n",
    "### Почему они особенные?\n",
    "\n",
    "Обычные модели для эмбеддинга текста (вроде тех, что используются в поиске Google) плохо понимают код. Специализированные code-embedding модели обучаются улавливать:\n",
    "*   **Синтаксис:** Важность скобок, отступов, ключевых слов.\n",
    "*   **Логику выполнения:** Что `for item in items` — это цикл.\n",
    "*   **Зависимости:** Что изменение одной переменной повлияет на другую.\n",
    "*   **Функциональность:** Что две функции, написанные по-разному, могут делать одно и то же.\n",
    "\n",
    "### Топовые модели (2024-2025)\n",
    "\n",
    "| Модель |Ключевые особенности | Область применения |\n",
    "| :--- | :--- | :--- |\n",
    "| **[VoyageCode-3](https://huggingface.co/voyageai/voyage-code-3)**  | 🏆 Лидер по качеству семантического поиска кода. | RAG для кода, поиск по смыслу. |\n",
    "| **[CodeXEmbed](https://huggingface.co/papers/2411.12644)** | 🌐 Open-source, поддерживает 12+ языков. | Универсальный поиск (код-текст, текст-код). |\n",
    "| **[Qodo-Embed-1](https://huggingface.co/Qodo/Qodo-Embed-1-7B)** | 🚀 SOTA на бенчмарке CoIR, использует синтетические данные. | Поиск кода (code retrieval). |\n",
    "| **[Jina Code V2](https://huggingface.co/jinaai/jina-embeddings-v2-base-code)** | ⚙️ Оптимизирован под паттерны использования API. | Автодополнение, анализ репозиториев. |\n",
    "| **OpenAI `text-embedding-3-large`** |  универсальная модель с хорошей поддержкой кода. | Гибридные задачи (текст + код). |\n",
    "\n",
    "### Как их обучают? \n",
    "\n",
    "1.  **Контрастивное обучение с AST-трансформациями**\n",
    "    Это самый продвинутый метод. Модель учится отличать семантически одинаковый код от разного.\n",
    "    *   **Anchor (Якорь):** Исходная функция.\n",
    "    *   **Positive (Позитивный пример):** Та же функция, но с измененными именами переменных, другим стилем форматирования (семантика сохранена).\n",
    "    *   **Negative (Негативный пример):** Совершенно другие функции.\n",
    "\n",
    "    Модель штрафуют, если вектор \"якоря\" далек от \"позитивного\" или близок к \"негативному\".\n",
    "\n",
    "    ```python\n",
    "    # Anchor:\n",
    "    def original_function(items):\n",
    "        result = []\n",
    "        for item in items:\n",
    "            result.append(item * 2)\n",
    "        return result\n",
    "\n",
    "    # Positive Sample (семантически эквивалентен):\n",
    "    def transformed_function(data):\n",
    "        output = [element * 2 for element in data]\n",
    "        return output\n",
    "    ```\n",
    "\n",
    "2.  **Мульти-задачное обучение (Multi-task Training)**\n",
    "    Модель (`CodeXEmbed`) обучается сразу нескольким задачам, которые сводятся к поиску:\n",
    "    *   **Код ➡️ Текст:** Найди документацию для этой функции.\n",
    "    *   **Текст ➡️ Код:** Найди функцию по этому описанию.\n",
    "    *   **Код ➡️ Код:** Найди похожие по функциональности функции.\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"docs/code_emb_training.png\" alt=\"alt text\" style=\"width:400px;\">\n",
    "</div>\n",
    "\n",
    "3.  **Генерация синтетических данных**\n",
    "    Подход (`Qodo-Embed-1`). Большая LLM (например, GPT-4) используется для генерации тысяч пар \"описание на естественном языке ↔️ фрагмент кода\". Это позволяет модели лучше понимать человеческие запросы о коде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd929d-438e-4f27-b5d5-7dd3077f41fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f657005-1fbe-436e-94b2-c3c8620bc8b7",
   "metadata": {},
   "source": [
    "## Продвинутые подходы к чанкингу\n",
    "\n",
    "\"Как порезать слона?\" — главный вопрос RAG. Простое разбиение кода по 500 символов не работает, так как разрывает логические блоки. Поэтому используются умные стратегии.\n",
    "\n",
    "### 1. Семантический чанкинг (Content-Aware Chunking)\n",
    "\n",
    "Система использует парсеры кода (как в компиляторах), чтобы разбивать файлы не по тексту, а по структуре:\n",
    "*   **Уровень функций/методов:** Каждая функция — отдельный чанк.\n",
    "*   **Уровень классов:** Весь класс с его методами — один чанк.\n",
    "*   **Уровень модулей:** Группировка связанных импортов и глобальных переменных.\n",
    "\n",
    "### 2. Иерархический чанкинг\n",
    "\n",
    "Создается многоуровневое представление кода для гибкого поиска.\n",
    "*   **Макро-уровень (1000-2000 токенов):** Целые файлы или большие классы. Дают общий контекст.\n",
    "*   **Микро-уровень (200-500 токенов):** Отдельные функции или методы. Дают конкретную реализацию.\n",
    "*   **Нано-уровень (50-100 токенов):** Отдельные выражения или логические блоки. Для очень точечных вопросов.\n",
    "\n",
    "### 3. Стратегии \"перекрытия\" (Overlap)\n",
    "\n",
    "Чтобы чанки не теряли контекст на границах, они создаются с перекрытием, которое захватывает важную информацию из соседей.\n",
    "*   **Синтаксическое перекрытие:** В чанк включается объявление переменных из предыдущего блока.\n",
    "*   **Контекстное перекрытие:** В чанк всегда включаются docstring'и и комментарии, относящиеся к нему.\n",
    "*   **Зависимостное перекрытие:** В чанк с функцией добавляются ключевые импорты из начала файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c87bb475-a100-4616-84d3-ad8606fedb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим на практическом примере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9ea40695-2e99-4eb5-a949-1fa15d7039e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain, langchain_community\n",
    "import os, ast, re\n",
    "from typing import List, Dict, Any, Optional\n",
    "import tiktoken\n",
    "from dataclasses import dataclass\n",
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f180e930-1769-4fd8-9011-3305d3fef5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken 0.9.0\n",
      "langchain 0.3.25\n",
      "langchain_community 0.3.25\n"
     ]
    }
   ],
   "source": [
    "print(\"tiktoken\", tiktoken.__version__)\n",
    "print(\"langchain\", langchain.__version__)\n",
    "print(\"langchain_community\", langchain_community.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eafc28-cec9-42f7-a952-e2bb39f10eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CodeChunk:\n",
    "    \"\"\"Enhanced code chunk with semantic metadata\"\"\"\n",
    "    content: str\n",
    "    file_path: str\n",
    "    function_name: Optional[str] = None\n",
    "    class_name: Optional[str] = None\n",
    "    line_start: int = 0\n",
    "    line_end: int = 0\n",
    "    dependencies: List[str] = None\n",
    "    chunk_type: str = \"general\"  # function, class, import, comment\n",
    "\n",
    "class AdvancedCodeChunker:\n",
    "    \"\"\"Production-ready code chunking with multiple strategies\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"BAAI/bge-code-base\"):\n",
    "        # Используем специализированную модель для кода вместо general-purpose\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs={'device': 'cpu'},\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "        \n",
    "        # Токенизатор для точного подсчета токенов\n",
    "        self.encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        \n",
    "        # Различные стратегии chunking\n",
    "        self.strategies = {\n",
    "            'semantic': self._semantic_chunking,\n",
    "            'hybrid': self._hybrid_chunking,\n",
    "            'function_based': self._function_based_chunking\n",
    "        }\n",
    "    \n",
    "    def _count_tokens(self, text: str) -> int:\n",
    "        \"\"\"Точный подсчет токенов\"\"\"\n",
    "        return len(self.encoding.encode(text))\n",
    "    \n",
    "    def _extract_functions_and_classes(self, code: str, file_path: str) -> List[CodeChunk]:\n",
    "        \"\"\"Извлекает функции и классы как отдельные чанки\"\"\"\n",
    "        chunks = []\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "            lines = code.split('\\n')\n",
    "            \n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                    start_line = node.lineno - 1\n",
    "                    end_line = node.end_lineno if hasattr(node, 'end_lineno') else start_line + 10\n",
    "                    \n",
    "                    func_code = '\\n'.join(lines[start_line:end_line])\n",
    "                    \n",
    "                    # Извлекаем зависимости (вызовы других функций)\n",
    "                    dependencies = []\n",
    "                    for call_node in ast.walk(node):\n",
    "                        if isinstance(call_node, ast.Call) and isinstance(call_node.func, ast.Name):\n",
    "                            dependencies.append(call_node.func.id)\n",
    "                    \n",
    "                    chunks.append(CodeChunk(\n",
    "                        content=func_code,\n",
    "                        file_path=file_path,\n",
    "                        function_name=node.name,\n",
    "                        line_start=start_line,\n",
    "                        line_end=end_line,\n",
    "                        dependencies=dependencies,\n",
    "                        chunk_type=\"function\"\n",
    "                    ))\n",
    "                    \n",
    "                elif isinstance(node, ast.ClassDef):\n",
    "                    start_line = node.lineno - 1\n",
    "                    end_line = node.end_lineno if hasattr(node, 'end_lineno') else start_line + 20\n",
    "                    \n",
    "                    class_code = '\\n'.join(lines[start_line:end_line])\n",
    "                    chunks.append(CodeChunk(\n",
    "                        content=class_code,\n",
    "                        file_path=file_path,\n",
    "                        class_name=node.name,\n",
    "                        line_start=start_line,\n",
    "                        line_end=end_line,\n",
    "                        chunk_type=\"class\"\n",
    "                    ))\n",
    "                    \n",
    "        except SyntaxError:\n",
    "            # Fallback для некорректного кода\n",
    "            return self._fallback_chunking(code, file_path)\n",
    "            \n",
    "        return chunks\n",
    "    \n",
    "    def _semantic_chunking(self, code: str, file_path: str, target_size: int = 400) -> List[CodeChunk]:\n",
    "        \"\"\"Семантический chunking с учетом структуры кода\"\"\"\n",
    "        chunks = []\n",
    "        \n",
    "        # Сначала пробуем извлечь функции и классы\n",
    "        semantic_chunks = self._extract_functions_and_classes(code, file_path)\n",
    "        \n",
    "        for chunk in semantic_chunks:\n",
    "            token_count = self._count_tokens(chunk.content)\n",
    "            \n",
    "            if token_count <= target_size:\n",
    "                chunks.append(chunk)\n",
    "            else:\n",
    "                # Слишком большие функции разбиваем дальше\n",
    "                sub_chunks = self._split_large_function(chunk, target_size)\n",
    "                chunks.extend(sub_chunks)\n",
    "        \n",
    "        # Обрабатываем оставшийся код (импорты, глобальные переменные)\n",
    "        remaining_code = self._extract_remaining_code(code, semantic_chunks)\n",
    "        if remaining_code.strip():\n",
    "            chunks.append(CodeChunk(\n",
    "                content=remaining_code,\n",
    "                file_path=file_path,\n",
    "                chunk_type=\"imports_globals\"\n",
    "            ))\n",
    "            \n",
    "        return chunks\n",
    "    \n",
    "    def _hybrid_chunking(self, code: str, file_path: str, target_size: int = 300) -> List[CodeChunk]:\n",
    "        \"\"\"Гибридный подход: semantic + overlap-based\"\"\"\n",
    "        semantic_chunks = self._semantic_chunking(code, file_path, target_size)\n",
    "        \n",
    "        # Добавляем overlap между связанными чанками\n",
    "        enhanced_chunks = []\n",
    "        \n",
    "        for i, chunk in enumerate(semantic_chunks):\n",
    "            enhanced_content = chunk.content\n",
    "            \n",
    "            # Добавляем контекст из предыдущего чанка\n",
    "            if i > 0 and semantic_chunks[i-1].chunk_type in [\"function\", \"class\"]:\n",
    "                prev_signature = self._extract_signature(semantic_chunks[i-1].content)\n",
    "                if prev_signature:\n",
    "                    enhanced_content = f\"# Previous context:\\n{prev_signature}\\n\\n{enhanced_content}\"\n",
    "            \n",
    "            # Добавляем импорты если их нет\n",
    "            if chunk.chunk_type == \"function\" and not self._has_imports(chunk.content):\n",
    "                imports = self._extract_imports(code)\n",
    "                if imports:\n",
    "                    enhanced_content = f\"{imports}\\n\\n{enhanced_content}\"\n",
    "            \n",
    "            enhanced_chunks.append(CodeChunk(\n",
    "                content=enhanced_content,\n",
    "                file_path=chunk.file_path,\n",
    "                function_name=chunk.function_name,\n",
    "                class_name=chunk.class_name,\n",
    "                line_start=chunk.line_start,\n",
    "                line_end=chunk.line_end,\n",
    "                dependencies=chunk.dependencies,\n",
    "                chunk_type=chunk.chunk_type\n",
    "            ))\n",
    "            \n",
    "        return enhanced_chunks\n",
    "    \n",
    "    def _extract_signature(self, code: str) -> Optional[str]:\n",
    "        \"\"\"Извлекает сигнатуру функции/класса\"\"\"\n",
    "        lines = code.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(('def ', 'class ', 'async def ')):\n",
    "                return line.strip()\n",
    "        return None\n",
    "    \n",
    "    def _has_imports(self, code: str) -> bool:\n",
    "        \"\"\"Проверяет наличие импортов в коде\"\"\"\n",
    "        return bool(re.search(r'^\\s*(import|from)\\s+', code, re.MULTILINE))\n",
    "    \n",
    "    def _extract_imports(self, code: str) -> str:\n",
    "        \"\"\"Извлекает все импорты из кода\"\"\"\n",
    "        lines = code.split('\\n')\n",
    "        imports = []\n",
    "        for line in lines:\n",
    "            if re.match(r'^\\s*(import|from)\\s+', line):\n",
    "                imports.append(line)\n",
    "        return '\\n'.join(imports)\n",
    "    \n",
    "    def process_codebase(self, codebase: Dict[str, str], \n",
    "                        strategy: str = \"hybrid\", \n",
    "                        target_size: int = 300) -> List[Document]:\n",
    "        \"\"\"Обрабатывает всю кодовую базу\"\"\"\n",
    "        \n",
    "        all_chunks = []\n",
    "        chunking_func = self.strategies.get(strategy, self._hybrid_chunking)\n",
    "        \n",
    "        for file_path, code in codebase.items():\n",
    "            file_chunks = chunking_func(code, file_path, target_size)\n",
    "            \n",
    "            # Конвертируем в LangChain Documents\n",
    "            for chunk in file_chunks:\n",
    "                doc = Document(\n",
    "                    page_content=chunk.content,\n",
    "                    metadata={\n",
    "                        'file': chunk.file_path,\n",
    "                        'function_name': chunk.function_name,\n",
    "                        'class_name': chunk.class_name,\n",
    "                        'chunk_type': chunk.chunk_type,\n",
    "                        'line_start': chunk.line_start,\n",
    "                        'line_end': chunk.line_end,\n",
    "                        'dependencies': chunk.dependencies or [],\n",
    "                        'token_count': self._count_tokens(chunk.content)\n",
    "                    }\n",
    "                )\n",
    "                all_chunks.append(doc)\n",
    "        \n",
    "        return all_chunks\n",
    "    \n",
    "    # Helper methods\n",
    "    def _split_large_function(self, chunk: CodeChunk, target_size: int) -> List[CodeChunk]:\n",
    "        \"\"\"Разбивает большие функции на меньшие части\"\"\"\n",
    "        # Упрощенная версия - можно расширить\n",
    "        splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "            language=Language.PYTHON,\n",
    "            chunk_size=target_size,\n",
    "            chunk_overlap=50,\n",
    "            length_function=self._count_tokens\n",
    "        )\n",
    "        \n",
    "        docs = splitter.create_documents([chunk.content])\n",
    "        sub_chunks = []\n",
    "        \n",
    "        for i, doc in enumerate(docs):\n",
    "            sub_chunks.append(CodeChunk(\n",
    "                content=doc.page_content,\n",
    "                file_path=chunk.file_path,\n",
    "                function_name=f\"{chunk.function_name}_part_{i+1}\",\n",
    "                chunk_type=\"function_part\",\n",
    "                dependencies=chunk.dependencies\n",
    "            ))\n",
    "        \n",
    "        return sub_chunks\n",
    "    \n",
    "    def _extract_remaining_code(self, code: str, processed_chunks: List[CodeChunk]) -> str:\n",
    "        \"\"\"Извлекает код, не попавший в функции/классы\"\"\"\n",
    "        lines = code.split('\\n')\n",
    "        processed_lines = set()\n",
    "        \n",
    "        for chunk in processed_chunks:\n",
    "            for line_num in range(chunk.line_start, chunk.line_end + 1):\n",
    "                if line_num < len(lines):\n",
    "                    processed_lines.add(line_num)\n",
    "        \n",
    "        remaining_lines = []\n",
    "        for i, line in enumerate(lines):\n",
    "            if i not in processed_lines and line.strip():\n",
    "                remaining_lines.append(line)\n",
    "        \n",
    "        return '\\n'.join(remaining_lines)\n",
    "    \n",
    "    def _fallback_chunking(self, code: str, file_path: str) -> List[CodeChunk]:\n",
    "        \"\"\"Fallback chunking для проблематичного кода\"\"\"\n",
    "        splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "            language=Language.PYTHON,\n",
    "            chunk_size=300,\n",
    "            chunk_overlap=30\n",
    "        )\n",
    "        \n",
    "        docs = splitter.create_documents([code])\n",
    "        return [CodeChunk(content=doc.page_content, file_path=file_path) for doc in docs]\n",
    "    \n",
    "    def _function_based_chunking(self, code: str, file_path: str, target_size: int = 400) -> List[CodeChunk]:\n",
    "        \"\"\"Простой function-based chunking\"\"\"\n",
    "        return self._extract_functions_and_classes(code, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da869cc-7b28-4631-ada0-5e1de9034403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# это наша кодовая база\n",
    "codebase = {\n",
    "    \"user_service.py\": \"\"\"\n",
    "        import logging\n",
    "        from typing import Optional, List\n",
    "        from database import get_database_connection, Database\n",
    "        \n",
    "        logger = logging.getLogger(__name__)\n",
    "        \n",
    "        class UserAPI:\n",
    "            \\\"\\\"\\\"API for user operations\\\"\\\"\\\"\n",
    "            \n",
    "            def __init__(self, db_config: dict):\n",
    "                self.db_config = db_config\n",
    "                self.cache = {}\n",
    "            \n",
    "            def get_user(self, user_id: int) -> Optional[dict]:\n",
    "                \\\"\\\"\\\"Retrieves user from the database\\\"\\\"\\\"\n",
    "                if user_id in self.cache:\n",
    "                    logger.info(f\"Cache hit for user {user_id}\")\n",
    "                    return self.cache[user_id]\n",
    "                    \n",
    "                db = get_database_connection()\n",
    "                user_data = db.query(f'SELECT * FROM users WHERE id = {user_id}')\n",
    "                \n",
    "                if user_data:\n",
    "                    self.cache[user_id] = user_data\n",
    "                    logger.info(f\"User {user_id} loaded from database\")\n",
    "                \n",
    "                return user_data\n",
    "            \n",
    "            def create_user(self, username: str, email: str) -> dict:\n",
    "                \\\"\\\"\\\"Creates a new user\\\"\\\"\\\"\n",
    "                db = get_database_connection()\n",
    "                query = f\"INSERT INTO users (username, email) VALUES ('{username}', '{email}')\"\n",
    "                result = db.execute(query)\n",
    "                \n",
    "                new_user = {\n",
    "                    'id': result.lastrowid,\n",
    "                    'username': username, \n",
    "                    'email': email\n",
    "                }\n",
    "                \n",
    "                # Очищаем кэш\n",
    "                self.cache.clear()\n",
    "                logger.info(f\"Created user: {username}\")\n",
    "                return new_user\n",
    "    \"\"\",\n",
    "    \"database.py\": \"\"\"\n",
    "        import os\n",
    "        import sqlite3\n",
    "        from typing import Optional, Any\n",
    "        import logging\n",
    "        \n",
    "        logger = logging.getLogger(__name__)\n",
    "        \n",
    "        class Database:\n",
    "            \\\"\\\"\\\"Database connection wrapper\\\"\\\"\\\"\n",
    "            \n",
    "            def __init__(self, db_path: str = \"app.db\"):\n",
    "                self.db_path = db_path\n",
    "                self.connection = None\n",
    "                self._connect()\n",
    "            \n",
    "            def _connect(self):\n",
    "                \\\"\\\"\\\"Establish database connection\\\"\\\"\\\"\n",
    "                try:\n",
    "                    self.connection = sqlite3.connect(self.db_path)\n",
    "                    self.connection.row_factory = sqlite3.Row\n",
    "                    logger.info(f\"Connected to database: {self.db_path}\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Database connection failed: {e}\")\n",
    "                    raise\n",
    "            \n",
    "            def query(self, sql: str) -> Optional[dict]:\n",
    "                \\\"\\\"\\\"Execute SELECT query\\\"\\\"\\\"\n",
    "                logger.debug(f\"Executing query: {sql}\")\n",
    "                try:\n",
    "                    cursor = self.connection.cursor()\n",
    "                    cursor.execute(sql)\n",
    "                    result = cursor.fetchone()\n",
    "                    return dict(result) if result else None\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Query failed: {e}\")\n",
    "                    return None\n",
    "            \n",
    "            def execute(self, sql: str) -> Any:\n",
    "                \\\"\\\"\\\"Execute INSERT/UPDATE/DELETE query\\\"\\\"\\\"\n",
    "                logger.debug(f\"Executing: {sql}\")\n",
    "                try:\n",
    "                    cursor = self.connection.cursor()\n",
    "                    cursor.execute(sql)\n",
    "                    self.connection.commit()\n",
    "                    return cursor\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Execute failed: {e}\")\n",
    "                    self.connection.rollback()\n",
    "                    raise\n",
    "        \n",
    "        # Singleton instance\n",
    "        _db_instance = None\n",
    "        \n",
    "        def get_database_connection() -> Database:\n",
    "            \\\"\\\"\\\"Returns a database connection singleton\\\"\\\"\\\"\n",
    "            global _db_instance\n",
    "            if _db_instance is None:\n",
    "                db_path = os.getenv('DB_PATH', 'default.db')\n",
    "                _db_instance = Database(db_path)\n",
    "            return _db_instance\n",
    "    \"\"\",\n",
    "    \"config.py\": \"\"\"\n",
    "        import os\n",
    "        from dataclasses import dataclass\n",
    "        \n",
    "        @dataclass\n",
    "        class AppConfig:\n",
    "            debug: bool = False\n",
    "            db_path: str = \"app.db\"\n",
    "            log_level: str = \"INFO\"\n",
    "            cache_size: int = 1000\n",
    "        \n",
    "        def load_config() -> AppConfig:\n",
    "            return AppConfig(\n",
    "                debug=os.getenv('DEBUG', 'False').lower() == 'true',\n",
    "                db_path=os.getenv('DB_PATH', 'app.db'),\n",
    "                log_level=os.getenv('LOG_LEVEL', 'INFO'),\n",
    "                cache_size=int(os.getenv('CACHE_SIZE', '1000'))\n",
    "            )\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c26c4619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c136ad3b1ff4ea2b604774cb5f95891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Стратегия: SEMANTIC ---\n",
      "Создано 15 чанков\n",
      "Распределение по типам:\n",
      "  class: 3\n",
      "  function: 9\n",
      "  imports_globals: 3\n",
      "Средний размер чанка: 87.3 токенов\n",
      "\n",
      "Запрос: Как создается подключение к базе данных?\n",
      "Найденные чанки:\n",
      "  1. user_service.py (imports_globals)\n",
      "      Размер: 26 токенов\n",
      "      Превью: import logging\n",
      "from typing import Optional, List\n",
      "from database import get_database_connection, Datab...\n",
      "  2. config.py (function)\n",
      "      Функция: load_config\n",
      "      Размер: 68 токенов\n",
      "      Превью: def load_config() -> AppConfig:\n",
      "    return AppConfig(\n",
      "        debug=os.getenv('DEBUG', 'False').lowe...\n",
      "  3. database.py (class)\n",
      "      Размер: 278 токенов\n",
      "      Превью: class Database:\n",
      "    \"\"\"Database connection wrapper\"\"\"\n",
      "\n",
      "    def __init__(self, db_path: str = \"app.db...\n",
      "\n",
      "Запрос: Где используется кэширование пользователей?\n",
      "Найденные чанки:\n",
      "  1. config.py (class)\n",
      "      Размер: 38 токенов\n",
      "      Превью: class AppConfig:\n",
      "    debug: bool = False\n",
      "    db_path: str = \"app.db\"\n",
      "    log_level: str = \"INFO\"\n",
      "   ...\n",
      "  2. user_service.py (imports_globals)\n",
      "      Размер: 26 токенов\n",
      "      Превью: import logging\n",
      "from typing import Optional, List\n",
      "from database import get_database_connection, Datab...\n",
      "  3. user_service.py (class)\n",
      "      Размер: 271 токенов\n",
      "      Превью: class UserAPI:\n",
      "    \"\"\"API for user operations\"\"\"\n",
      "\n",
      "    def __init__(self, db_config: dict):\n",
      "        s...\n",
      "\n",
      "Запрос: Какие есть функции для работы с пользователями?\n",
      "Найденные чанки:\n",
      "  1. user_service.py (imports_globals)\n",
      "      Размер: 26 токенов\n",
      "      Превью: import logging\n",
      "from typing import Optional, List\n",
      "from database import get_database_connection, Datab...\n",
      "  2. user_service.py (class)\n",
      "      Размер: 271 токенов\n",
      "      Превью: class UserAPI:\n",
      "    \"\"\"API for user operations\"\"\"\n",
      "\n",
      "    def __init__(self, db_config: dict):\n",
      "        s...\n",
      "  3. config.py (class)\n",
      "      Размер: 38 токенов\n",
      "      Превью: class AppConfig:\n",
      "    debug: bool = False\n",
      "    db_path: str = \"app.db\"\n",
      "    log_level: str = \"INFO\"\n",
      "   ...\n",
      "\n",
      "--- Стратегия: HYBRID ---\n",
      "Создано 15 чанков\n",
      "Распределение по типам:\n",
      "  class: 3\n",
      "  function: 9\n",
      "  imports_globals: 3\n",
      "Средний размер чанка: 108.1 токенов\n",
      "\n",
      "Запрос: Как создается подключение к базе данных?\n",
      "Найденные чанки:\n",
      "  1. user_service.py (imports_globals)\n",
      "      Размер: 46 токенов\n",
      "      Превью: # Previous context:\n",
      "def create_user(self, username: str, email: str) -> dict:\n",
      "\n",
      "import logging\n",
      "from t...\n",
      "  2. config.py (function)\n",
      "      Функция: load_config\n",
      "      Размер: 85 токенов\n",
      "      Превью: import os\n",
      "from dataclasses import dataclass\n",
      "\n",
      "# Previous context:\n",
      "class AppConfig:\n",
      "\n",
      "def load_config()...\n",
      "  3. database.py (function)\n",
      "      Функция: query\n",
      "      Размер: 108 токенов\n",
      "      Превью: import os\n",
      "import sqlite3\n",
      "from typing import Optional, Any\n",
      "import logging\n",
      "\n",
      "# Previous context:\n",
      "def _c...\n",
      "\n",
      "Запрос: Где используется кэширование пользователей?\n",
      "Найденные чанки:\n",
      "  1. config.py (function)\n",
      "      Функция: load_config\n",
      "      Размер: 85 токенов\n",
      "      Превью: import os\n",
      "from dataclasses import dataclass\n",
      "\n",
      "# Previous context:\n",
      "class AppConfig:\n",
      "\n",
      "def load_config()...\n",
      "  2. user_service.py (imports_globals)\n",
      "      Размер: 46 токенов\n",
      "      Превью: # Previous context:\n",
      "def create_user(self, username: str, email: str) -> dict:\n",
      "\n",
      "import logging\n",
      "from t...\n",
      "  3. config.py (class)\n",
      "      Размер: 38 токенов\n",
      "      Превью: class AppConfig:\n",
      "    debug: bool = False\n",
      "    db_path: str = \"app.db\"\n",
      "    log_level: str = \"INFO\"\n",
      "   ...\n",
      "\n",
      "Запрос: Какие есть функции для работы с пользователями?\n",
      "Найденные чанки:\n",
      "  1. user_service.py (imports_globals)\n",
      "      Размер: 46 токенов\n",
      "      Превью: # Previous context:\n",
      "def create_user(self, username: str, email: str) -> dict:\n",
      "\n",
      "import logging\n",
      "from t...\n",
      "  2. user_service.py (function)\n",
      "      Функция: create_user\n",
      "      Размер: 158 токенов\n",
      "      Превью: import logging\n",
      "from typing import Optional, List\n",
      "from database import get_database_connection, Datab...\n",
      "  3. user_service.py (function)\n",
      "      Функция: get_user\n",
      "      Размер: 148 токенов\n",
      "      Превью: import logging\n",
      "from typing import Optional, List\n",
      "from database import get_database_connection, Datab...\n",
      "\n",
      "--- Стратегия: FUNCTION_BASED ---\n",
      "Создано 12 чанков\n",
      "Распределение по типам:\n",
      "  class: 3\n",
      "  function: 9\n",
      "Средний размер чанка: 103.2 токенов\n",
      "\n",
      "Запрос: Как создается подключение к базе данных?\n",
      "Найденные чанки:\n",
      "  1. config.py (function)\n",
      "      Функция: load_config\n",
      "      Размер: 68 токенов\n",
      "      Превью: def load_config() -> AppConfig:\n",
      "    return AppConfig(\n",
      "        debug=os.getenv('DEBUG', 'False').lowe...\n",
      "  2. database.py (class)\n",
      "      Размер: 278 токенов\n",
      "      Превью: class Database:\n",
      "    \"\"\"Database connection wrapper\"\"\"\n",
      "\n",
      "    def __init__(self, db_path: str = \"app.db...\n",
      "  3. user_service.py (class)\n",
      "      Размер: 271 токенов\n",
      "      Превью: class UserAPI:\n",
      "    \"\"\"API for user operations\"\"\"\n",
      "\n",
      "    def __init__(self, db_config: dict):\n",
      "        s...\n",
      "\n",
      "Запрос: Где используется кэширование пользователей?\n",
      "Найденные чанки:\n",
      "  1. config.py (class)\n",
      "      Размер: 38 токенов\n",
      "      Превью: class AppConfig:\n",
      "    debug: bool = False\n",
      "    db_path: str = \"app.db\"\n",
      "    log_level: str = \"INFO\"\n",
      "   ...\n",
      "  2. user_service.py (class)\n",
      "      Размер: 271 токенов\n",
      "      Превью: class UserAPI:\n",
      "    \"\"\"API for user operations\"\"\"\n",
      "\n",
      "    def __init__(self, db_config: dict):\n",
      "        s...\n",
      "  3. user_service.py (function)\n",
      "      Функция: create_user\n",
      "      Размер: 120 токенов\n",
      "      Превью:     def create_user(self, username: str, email: str) -> dict:\n",
      "        \"\"\"Creates a new user\"\"\"\n",
      "     ...\n",
      "\n",
      "Запрос: Какие есть функции для работы с пользователями?\n",
      "Найденные чанки:\n",
      "  1. user_service.py (class)\n",
      "      Размер: 271 токенов\n",
      "      Превью: class UserAPI:\n",
      "    \"\"\"API for user operations\"\"\"\n",
      "\n",
      "    def __init__(self, db_config: dict):\n",
      "        s...\n",
      "  2. config.py (class)\n",
      "      Размер: 38 токенов\n",
      "      Превью: class AppConfig:\n",
      "    debug: bool = False\n",
      "    db_path: str = \"app.db\"\n",
      "    log_level: str = \"INFO\"\n",
      "   ...\n",
      "  3. user_service.py (function)\n",
      "      Функция: create_user\n",
      "      Размер: 120 токенов\n",
      "      Превью:     def create_user(self, username: str, email: str) -> dict:\n",
      "        \"\"\"Creates a new user\"\"\"\n",
      "     ...\n"
     ]
    }
   ],
   "source": [
    "# будем использовать эту модель эмбедингов\n",
    "chunker = AdvancedCodeChunker(model_name=\"BAAI/bge-code-v1\")\n",
    "\n",
    "# Обработка с разными стратегиями\n",
    "strategies = [\"semantic\", \"hybrid\", \"function_based\"]\n",
    "\n",
    "for strategy in strategies:\n",
    "    print(f\"\\n--- Стратегия: {strategy.upper()} ---\")\n",
    "    \n",
    "    # Обрабатываем кодовую базу\n",
    "    docs = chunker.process_codebase(codebase, strategy=strategy, target_size=350)\n",
    "    \n",
    "    print(f\"Создано {len(docs)} чанков\")\n",
    "    \n",
    "    # Показываем статистику по типам чанков\n",
    "    chunk_types = {}\n",
    "    token_stats = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        chunk_type = doc.metadata['chunk_type']\n",
    "        chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1\n",
    "        token_stats.append(doc.metadata['token_count'])\n",
    "    \n",
    "    print(\"Распределение по типам:\")\n",
    "    for chunk_type, count in chunk_types.items():\n",
    "        print(f\"  {chunk_type}: {count}\")\n",
    "    \n",
    "    if token_stats:\n",
    "        avg_tokens = sum(token_stats) / len(token_stats)\n",
    "        print(f\"Средний размер чанка: {avg_tokens:.1f} токенов\")\n",
    "    \n",
    "    # Создаем vectorstore и тестируем поиск\n",
    "    try:\n",
    "        vectorstore = FAISS.from_documents(docs, chunker.embeddings)\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "        \n",
    "        # Тестовые запросы\n",
    "        test_queries = [\n",
    "            \"Как создается подключение к базе данных?\",\n",
    "            \"Где используется кэширование пользователей?\", \n",
    "            \"Какие есть функции для работы с пользователями?\"\n",
    "        ]\n",
    "        \n",
    "        for query in test_queries:\n",
    "            print(f\"\\nЗапрос: {query}\")\n",
    "            relevant_docs = retriever.invoke(query)\n",
    "            \n",
    "            print(\"Найденные чанки:\")\n",
    "            for i, doc in enumerate(relevant_docs, 1):\n",
    "                metadata = doc.metadata\n",
    "                print(f\"  {i}. {metadata['file']} ({metadata['chunk_type']})\")\n",
    "                if metadata.get('function_name'):\n",
    "                    print(f\"      Функция: {metadata['function_name']}\")\n",
    "                print(f\"      Размер: {metadata['token_count']} токенов\")\n",
    "                print(f\"      Превью: {doc.page_content[:100]}...\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при создании vectorstore: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "960bedd9-410c-415f-b6ef-a6cfdbb63adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем стратегию hybrid\n",
    "final_docs = chunker.process_codebase(codebase, strategy=\"hybrid\", target_size=300)\n",
    "vectorstore = FAISS.from_documents(final_docs, chunker.embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "user_question = \"Как функция get_user получает доступ к базе данных и использует кэширование?\"\n",
    "relevant_docs = retriever.invoke(user_question)\n",
    "\n",
    "# Формируем обогащенный контекст\n",
    "enriched_context = []\n",
    "for doc in relevant_docs:\n",
    "    meta = doc.metadata\n",
    "    context_header = f\"--- {meta['file']}\"\n",
    "    \n",
    "    if meta.get('function_name'):\n",
    "        context_header += f\" | Функция: {meta['function_name']}\"\n",
    "    if meta.get('class_name'):\n",
    "        context_header += f\" | Класс: {meta['class_name']}\"\n",
    "    if meta.get('dependencies'):\n",
    "        context_header += f\" | Зависимости: {', '.join(meta['dependencies'][:3])}\"\n",
    "    \n",
    "    context_header += f\" | Токены: {meta['token_count']} ---\"\n",
    "    \n",
    "    enriched_context.append(f\"{context_header}\\n{doc.page_content}\")\n",
    "\n",
    "final_context = \"\\n\\n\".join(enriched_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a5aa472e-6c82-4f22-bea3-8bc4e6142be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_prompt = f\"\"\"\n",
    "    # Code Analysis Task\n",
    "    ## User Question\n",
    "    {user_question}\n",
    "    \n",
    "    ## Retrieved Code Context\n",
    "    {final_context}\n",
    "    \n",
    "    ## Analysis Instructions\n",
    "    1. **Trace the execution flow** между найденными фрагментами кода\n",
    "    2. **Identify patterns** использования баз данных и кэширования  \n",
    "    3. **Explain dependencies** между компонентами\n",
    "    4. **Provide concrete examples** из найденного кода\n",
    "    \n",
    "    ## Expected Output Format\n",
    "    - **Основной ответ**: прямой ответ на вопрос\n",
    "    - **Code flow**: пошаговое объяснение выполнения\n",
    "    - **Key components**: список ключевых функций/классов\n",
    "    - **Potential improvements**: рекомендации по улучшению\n",
    "    Ответ:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2e12cad4-1abf-409b-ba87-0d65d4f26fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.Client().generate(model=\"qwen2.5-coder:14b\", prompt=advanced_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b9b8e007-a01f-4752-a8ad-28c81ad51e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как функция get_user получает доступ к базе данных и использует кэширование?\n"
     ]
    }
   ],
   "source": [
    "print(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "04bdcebf-1252-4ba9-9ce0-e8177043b446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Основной ответ\n",
      "Функция `get_user` получает доступ к базе данных, используя функцию `get_database_connection`, которая возвращает объект базы данных. Если запрошенный пользователь уже находится в кэше (`self.cache`), функция возвращает данные из кэша, что называется \"кэш-хитом\". Если пользователя нет в кэше, функция выполняет SQL-запрос для выборки пользователя из базы данных. После получения данных пользователь добавляется в кэш, чтобы последующие запросы этого пользователя могли быть обработаны быстрее.\n",
      "\n",
      "## Code flow\n",
      "1. Функция `get_user` принимает аргумент `user_id`.\n",
      "2. Проверяется наличие `user_id` в кэше (`self.cache`).\n",
      "3. Если `user_id` найден в кэше:\n",
      "   - Возвращаются данные из кэша.\n",
      "4. Если `user_id` не найден в кэше:\n",
      "   - Вызывается функция `get_database_connection`, которая возвращает объект базы данных.\n",
      "   - Функция выполняет SQL-запрос для выборки пользователя из базы данных (`db.query(f'SELECT * FROM users WHERE id = {user_id}')`).\n",
      "5. Если пользователь найден в базе данных, его данные добавляются в кэш (`self.cache[user_id] = user_data`).\n",
      "6. Возвращаются полученные данные.\n",
      "\n",
      "## Key components\n",
      "- **Функции**:\n",
      "  - `get_user`: Получает пользователя из базы данных с использованием кэша.\n",
      "  - `create_user`: Создает нового пользователя в базе данных и очищает кэш.\n",
      "  - `load_config`: Загружает конфигурацию приложения из переменных окружения.\n",
      "- **Классы**:\n",
      "  - `AppConfig`: Класс для хранения конфигурации приложения.\n",
      "- **Модули**:\n",
      "  - `database`: Предоставляет функцию `get_database_connection` для получения соединения с базой данных.\n",
      "\n",
      "## Potential improvements\n",
      "1. **SQL инъекция**: В текущей реализации функции `create_user` используется форматирование строк для SQL-запросов, что может привести к уязвимости SQL инъекции. Рекомендуется использовать параметризованные запросы.\n",
      "2. **Кэширование**: Кэш хранится в памяти (`self.cache`). Для больших объемов данных или высокой нагрузки может потребоваться более сложная система кэширования, например, использование Redis.\n",
      "3. **Логирование**: Логирование выполняется через модуль `logging`, что правильно. Однако, можно добавить более подробные логи для отслеживания работы кэша и базы данных.\n",
      "4. **Обработка ошибок**: В текущем коде нет обработки возможных ошибок при взаимодействии с базой данных. Рекомендуется добавить try-except блоки для обработки исключений.\n",
      "\n",
      "Эти улучшения повысят безопасность, производительность и надежность системы.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450c9a1-8c0a-45d9-81fb-ec5cf411368d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94984a5c-303e-4957-846f-f75a784a3f67",
   "metadata": {},
   "source": [
    "# Уровень 5: «Агенты» и автономные задачи  \n",
    "\n",
    "**Как это работает?**\n",
    "\n",
    "Это циклический процесс, часто описываемый фреймворком **ReAct (Reason + Act)**.\n",
    "\n",
    "- **Планирование (Reason)**: LLM получает вашу цель и разбивает ее на последовательность конкретных шагов: `\"1. Найти файл с роутами. 2. Добавить новый роут. 3. Создать файл контроллера. 4. Написать логику в контроллере...\"`.\n",
    "- **Использование инструментов (Act)**: У \"агента\" есть доступ к набору инструментов — API для взаимодействия со средой: `readFile(path)`, `writeFile(path, content)`, `findSymbol(name)`, `runTerminalCommand(command)`.\n",
    "- **Исполнение и наблюдение**: Агент выполняет первый шаг плана, используя нужный инструмент (например, `readFile('src/routes.js')`). Он получает результат (содержимое файла или ошибку) и анализирует его.\n",
    "- **Повторение цикла**: На основе результата агент корректирует свой план и переходит к следующему шагу. Этот цикл `\"Подумал -> Сделал -> Посмотрел на результат\"` продолжается до тех пор, пока задача не будет выполнена или агент не столкнется с проблемой, для решения которой ему нужна помощь человека.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"docs/react_1.png\" alt=\"alt text\" style=\"width:400px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "## Архитектурная карта code-агента\n",
    "\n",
    "### Базовые слои\n",
    "\n",
    "| Слой | Назначение | Ключевые компоненты |\n",
    "|------|------------|---------------------|\n",
    "| Интерфейс цели | Приём «high-level» запроса пользователя. | Form / API-endpoint, CLI, чат. |\n",
    "| Планировщик (*Reason*) | Декомпозирует цель в план действий. | Chain-of-Thought, Tree-of-Thought, Task-Tree генератор |\n",
    "| Исполнитель (*Act*) | Выбирает и запускает инструменты. | Tool Router, Sandbox executor, Terminal wrapper |\n",
    "| Обсервер (*Observation*) | Сохраняет результаты вызова, анализирует отклик/ошибку. | Diff-analyzer, Unit-tester, Lint-parser |\n",
    "| Память/Контекст | Долгосрочный и оперативный контекст для следующих шагов. | RAG-хранилище кода, векторная БД, кратковременный стек мыслей |\n",
    "| Менеджер цикла | Решает «завершить или продолжать», ограничивает итерации. | Stopping criteria, Cost-guard, Timeouts |\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"docs/multi_agents.png\" alt=\"alt text\" style=\"width:400px;\">\n",
    "</div>\n",
    "\n",
    "## Разновидности инструментов\n",
    "\n",
    "| Категория | Примеры вызовов | Типы задач |\n",
    "|-----------|-----------------|------------|\n",
    "| **Файловые** | `readFile`, `writeFile`, `appendFile` | Рефакторинг, вставка кода. |\n",
    "| **Семантический поиск** | `findSymbol`, `searchVector` | Быстрый RAG по кодовой базе. |\n",
    "| **Сборка / тесты** | `runTerminalCommand`, `npm test` | Верификация изменений. |\n",
    "| **Веб-APIs** | `httpRequest`, `getSwaggerSchema` | Интеграции и док-ген. |\n",
    "| **Кодогенерация** | `generateUnitTest`, `generateMigration` | Шаблоны, вспомогательный код. |\n",
    "| **Виртуальная песочница** | `pythonBox.exec`, `nodeSandbox.exec` | Безопасное выполнение фрагментов|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd69b31-1c0c-49ae-9140-de6f80b141a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92d46e11-e2b0-415b-916b-ab875a7f5626",
   "metadata": {},
   "source": [
    "### Вызовы и будущее AI-ассистентов\n",
    "\n",
    "Несмотря на впечатляющий прогресс, у текущих систем есть ограничения:\n",
    "- **\"Галлюцинации\"**: Модели могут генерировать несуществующий синтаксис или выдумывать несуществующие функции API.\n",
    "- **Безопасность**: Агент, имеющий доступ к терминалу и файловой системе, представляет потенциальный риск. Необходимо тщательно контролировать его полномочия.\n",
    "- **Ограниченный контекст**: Даже с RAG, модели все еще имеют ограниченное \"окно внимания\" и могут упускать общую картину в очень больших проектах.\n",
    "- **Высокая стоимость**: Запросы к самым мощным моделям (таким как GPT-4) могут быть дорогостоящими, особенно в агентном режиме, где выполняются десятки итераций.\n",
    "\n",
    "**Что нас ждет впереди?**\n",
    "- **Мультимодальность**: Ассистенты, способные понимать диаграммы, скриншоты и даже дизайн-макеты.\n",
    "- **Самовосстанавливающийся код**: Агенты, которые не только пишут код, но и автоматически исправляют баги на основе отчетов об ошибках.\n",
    "- **Глубокая персонализация**: Ассистенты, дообученные на вашем личном стиле кодирования и предпочтениях.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb047d1-9800-4142-b110-aaf064a0500a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a9d275c-2aac-4734-b982-3c4b6dd9042e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Заключение \n",
    "(переходим к следующей части семинара)\n",
    "\n",
    "Мы рассмотрели, как AI-ассистенты прошли путь от простого автодополнения до сложных систем, способных понимать кодовую базу и автономно выполнять задачи. Мы заглянули под капот ключевых технологий: FIM, AST-анализа, RAG и агентного подхода ReAct.\n",
    "\n",
    "Теперь, когда у нас есть теоретическая база, на следующей части семинара мы перейдем к самому интересному — **практическому созданию собственного coding agent фреймворка (или же: мультиагентной системы кодогенерации)** с использованием фреймворка AutoGen. Мы научим его планировать, использовать инструменты и решать реальные задачи по разработке автономно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "831d2cf0-213d-4eee-bbde-099fe3238ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well done\n"
     ]
    }
   ],
   "source": [
    "print('well done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea613c6-5737-4df6-bf8f-03d8d2ccc718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_jupyter",
   "language": "python",
   "name": "venv_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
