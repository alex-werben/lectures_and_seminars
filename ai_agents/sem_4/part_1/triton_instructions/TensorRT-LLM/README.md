# TensorRT-LLM + Triton Server Setup Guide

–≠—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ—à–∞–≥–æ–≤—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –∏ –∑–∞–ø—É—Å–∫—É TensorRT-LLM —Å Triton Inference Server –¥–ª—è –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π.

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ó–∞–ø—É—Å–∫ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞

```bash
docker run --gpus all -it --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  --name tensorrt_llama -p 8000:8000 -p 8001:8001 -p 8002:8002 \
  --volume C:\Users\tryma\triton_project:/workspace \
  --volume C:\Users\tryma\triton_project\hf_cache:/root/.cache/huggingface \
  --volume C:\Users\tryma\TensorRT-LLM:/workspace/TensorRT-LLM \
  --workdir /workspace nvcr.io/nvidia/tritonserver:25.06-trtllm-python-py3 /bin/bash
```

### 2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏

```bash
# –°–æ–∑–¥–∞–π—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞
mkdir -p /workspace/model_checkpoint

# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–π—Ç–µ –≤–∞—à—É –º–æ–¥–µ–ª—å llama3_2_1b_local
python3 /app/examples/models/core/llama/convert_checkpoint.py \
  --model_dir /workspace/local_models/llama3_2_1b_local \
  --output_dir /workspace/model_checkpoint \
  --dtype float16
```

### 3. –°–±–æ—Ä–∫–∞ TensorRT –¥–≤–∏–∂–∫–∞

```bash
# –°–æ–∑–¥–∞–π—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –¥–≤–∏–∂–∫–∞
mkdir -p /workspace/trt_engines

# –°–æ–±–µ—Ä–∏—Ç–µ TensorRT –¥–≤–∏–∂–æ–∫
trtllm-build --checkpoint_dir /workspace/model_checkpoint \
  --output_dir /workspace/trt_engines \
  --gemm_plugin float16 \
  --gpt_attention_plugin float16 \
  --remove_input_padding enable \
  --context_fmha enable \
  --paged_kv_cache enable \
  --max_batch_size 8 \
  --max_input_len 2048 \
  --max_seq_len 2560 \
  --max_num_tokens 4096
```

### 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Triton Server

```bash
# –°–æ–∑–¥–∞–π—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –º–æ–¥–µ–ª–µ–π
mkdir -p /workspace/model_repo

# –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —à–∞–±–ª–æ–Ω—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
cp -r /app/all_models/inflight_batcher_llm/* /workspace/model_repo/

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
export TOKENIZER_DIR="/workspace/local_models/llama3_2_1b_local" \
ENGINE_DIR="/workspace/trt_engines" \
MAX_BATCH_SIZE=8 \
INSTANCE_COUNT=1 \
DECOUPLED_MODE=false \
TRITON_BACKEND="tensorrtllm" \
LOGITS_DATATYPE="TYPE_FP32" \
MAX_QUEUE_DELAY_MS=0 \
MAX_QUEUE_SIZE=0 \
ADD_SPECIAL_TOKENS=True \
MAX_NUM_IMAGES=1 \
SKIP_SPECIAL_TOKENS=True \
MAX_BEAM_WIDTH=1 \
MAX_TOKENS_IN_PAGED_KV_CACHE=2560 \
MAX_ATTENTION_WINDOW_SIZE=2560 \
KV_CACHE_FREE_GPU_MEM_FRACTION=0.5 \
EXCLUDE_INPUT_IN_OUTPUT=True \
ENABLE_KV_CACHE_REUSE=False \
BATCHING_STRATEGY="inflight_fused_batching" \
MAX_QUEUE_DELAY_MICROSECONDS=0 \
GPU_DEVICE_IDS=0 \
ENCODER_INPUT_FEATURES_DATA_TYPE="TYPE_FP16"
```

### 5. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π

```bash
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
python3 /app/tools/fill_template.py -i /workspace/model_repo/preprocessing/config.pbtxt \
  tokenizer_dir:${TOKENIZER_DIR},triton_max_batch_size:${MAX_BATCH_SIZE},preprocessing_instance_count:${INSTANCE_COUNT},max_queue_delay_microseconds:${MAX_QUEUE_DELAY_MICROSECONDS},max_queue_size:${MAX_QUEUE_SIZE},add_special_tokens:${ADD_SPECIAL_TOKENS},engine_dir:${ENGINE_DIR},max_num_images:${MAX_NUM_IMAGES}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
python3 /app/tools/fill_template.py -i /workspace/model_repo/postprocessing/config.pbtxt \
  tokenizer_dir:${TOKENIZER_DIR},triton_max_batch_size:${MAX_BATCH_SIZE},postprocessing_instance_count:${INSTANCE_COUNT},skip_special_tokens:${SKIP_SPECIAL_TOKENS}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ BLS (Business Logic Scripting)
python3 /app/tools/fill_template.py -i /workspace/model_repo/tensorrt_llm_bls/config.pbtxt \
  triton_max_batch_size:${MAX_BATCH_SIZE},decoupled_mode:${DECOUPLED_MODE},bls_instance_count:${INSTANCE_COUNT},logits_datatype:${LOGITS_DATATYPE}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π
python3 /app/tools/fill_template.py -i /workspace/model_repo/ensemble/config.pbtxt \
  triton_max_batch_size:${MAX_BATCH_SIZE},logits_datatype:${LOGITS_DATATYPE}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ TensorRT-LLM
python3 /app/tools/fill_template.py -i /workspace/model_repo/tensorrt_llm/config.pbtxt \
  triton_backend:${TRITON_BACKEND},triton_max_batch_size:${MAX_BATCH_SIZE},decoupled_mode:${DECOUPLED_MODE},engine_dir:${ENGINE_DIR},batching_strategy:${BATCHING_STRATEGY},logits_datatype:${LOGITS_DATATYPE},max_beam_width:${MAX_BEAM_WIDTH},max_tokens_in_paged_kv_cache:${MAX_TOKENS_IN_PAGED_KV_CACHE},max_attention_window_size:${MAX_ATTENTION_WINDOW_SIZE},kv_cache_free_gpu_mem_fraction:${KV_CACHE_FREE_GPU_MEM_FRACTION},exclude_input_in_output:${EXCLUDE_INPUT_IN_OUTPUT},enable_kv_cache_reuse:${ENABLE_KV_CACHE_REUSE},max_queue_delay_microseconds:${MAX_QUEUE_DELAY_MICROSECONDS},encoder_input_features_data_type:${ENCODER_INPUT_FEATURES_DATA_TYPE},gpu_device_ids:${GPU_DEVICE_IDS}
```

### 6. –ó–∞–ø—É—Å–∫ Triton Server

```bash
python3 /app/scripts/launch_triton_server.py --world_size=1 --model_repo=/workspace/model_repo
```

## üìö –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –ö–æ–º–∞–Ω–¥–∞ `trtllm-build`

–ö–æ–º–∞–Ω–¥–∞ `trtllm-build` –∫–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å –≤ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –¥–≤–∏–∂–æ–∫ TensorRT-LLM:

```bash
trtllm-build --checkpoint_dir /workspace/model_checkpoint \
             --output_dir /workspace/trt_engines \
             --gemm_plugin float16 \
             --gpt_attention_plugin float16 \
             --remove_input_padding enable \
             --context_fmha enable \
             --paged_kv_cache enable \
             --max_batch_size 8 \
             --max_input_len 2048 \
             --max_seq_len 2560 \
             --max_num_tokens 4096
```

#### –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
- `--checkpoint_dir /workspace/model_checkpoint` - –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –≤–µ—Å–∞–º–∏ –∏—Å—Ö–æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
- `--output_dir /workspace/trt_engines` - –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–≤–∏–∂–∫–∞

#### –ü–ª–∞–≥–∏–Ω—ã –∏ —Ç–æ—á–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- `--gemm_plugin float16` - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å float16 –¥–ª—è –º–∞—Ç—Ä–∏—á–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- `--gpt_attention_plugin float16` - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å float16 –¥–ª—è –º–µ—Ö–∞–Ω–∏–∑–º–∞ –≤–Ω–∏–º–∞–Ω–∏—è

#### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- `--remove_input_padding enable` - –∏—Å–∫–ª—é—á–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–∞–¥–¥–∏–Ω–≥-—Ç–æ–∫–µ–Ω–æ–≤
- `--context_fmha enable` - –≤–∫–ª—é—á–∞–µ—Ç Fused Multi-Head Attention –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- `--paged_kv_cache enable` - –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é K/V –∫—ç—à–∞

#### –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤
- `--max_batch_size 8` - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- `--max_input_len 2048` - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
- `--max_seq_len 2560` - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ–±—â–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- `--max_num_tokens 4096` - –æ–±—â–∏–π –ø—É–ª —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è K/V –∫—ç—à–∞

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è Triton Server

#### –û—Å–Ω–æ–≤–Ω—ã–µ –ø—É—Ç–∏ –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
- `TOKENIZER_DIR` - –ø—É—Ç—å –∫ —Ñ–∞–π–ª–∞–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
- `ENGINE_DIR` - –ø—É—Ç—å –∫ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –¥–≤–∏–∂–∫—É TensorRT-LLM
- `TRITON_BACKEND` - –±—ç–∫–µ–Ω–¥ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (tensorrtllm)
- `GPU_DEVICE_IDS` - ID GPU –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

#### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
- `INSTANCE_COUNT` - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –º–æ–¥–µ–ª–∏ –Ω–∞ GPU
- `MAX_BATCH_SIZE` - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –±–∞—Ç—á–µ
- `BATCHING_STRATEGY` - —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –±–∞—Ç—á–∏–Ω–≥–∞ (inflight_fused_batching)
- `MAX_QUEUE_DELAY_MICROSECONDS` - –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞—Ç—á–∞

#### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é GPU
- `MAX_TOKENS_IN_PAGED_KV_CACHE` - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ K/V –∫—ç—à–µ
- `MAX_ATTENTION_WINDOW_SIZE` - —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –≤–Ω–∏–º–∞–Ω–∏—è
- `KV_CACHE_FREE_GPU_MEM_FRACTION` - –¥–æ–ª—è —Å–≤–æ–±–æ–¥–Ω–æ–π –ø–∞–º—è—Ç–∏ –¥–ª—è K/V –∫—ç—à–∞

#### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- `DECOUPLED_MODE` - —Ä–µ–∂–∏–º –æ—Ç–≤–µ—Ç–∞ —Å–µ—Ä–≤–µ—Ä–∞ (false –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞)
- `LOGITS_DATATYPE` - —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ª–æ–≥–∏—Ç–æ–≤
- `ADD_SPECIAL_TOKENS` - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
- `SKIP_SPECIAL_TOKENS` - –ø—Ä–æ–ø—É—Å–∫ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
- `MAX_BEAM_WIDTH` - —à–∏—Ä–∏–Ω–∞ –ª—É—á–∞ –¥–ª—è Beam Search
- `EXCLUDE_INPUT_IN_OUTPUT` - –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞
- `ENABLE_KV_CACHE_REUSE` - –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ K/V –∫—ç—à–∞

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥ –≤–∞—à–∏ –Ω—É–∂–¥—ã

### –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏
–î–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ —Ä–∞–∑–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–º–µ–Ω–∏—Ç–µ:
- `MAX_BATCH_SIZE` - –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–π VRAM
- `MAX_INPUT_LEN` –∏ `MAX_SEQ_LEN` - –ø–æ–¥ –≤–∞—à–∏ –∑–∞–¥–∞—á–∏
- `KV_CACHE_FREE_GPU_MEM_FRACTION` - –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- –£–≤–µ–ª–∏—á—å—Ç–µ `INSTANCE_COUNT` –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ `MAX_QUEUE_DELAY_MICROSECONDS` –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ latency/throughput
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `ENABLE_KV_CACHE_REUSE=True` –¥–ª—è –º–Ω–æ–≥–æ—Ö–æ–¥–æ–≤—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤

## üö® –í–∞–∂–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è

1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ VRAM –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
2. –ó–Ω–∞—á–µ–Ω–∏—è `MAX_BATCH_SIZE` –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å –≤ –∫–æ–º–∞–Ω–¥–µ —Å–±–æ—Ä–∫–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ Triton
3. –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–ª—è –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã
4. –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

## üìñ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [TensorRT-LLM Documentation](https://github.com/NVIDIA/TensorRT-LLM)
- [Triton Inference Server](https://github.com/triton-inference-server/server)
- [NVIDIA NGC Containers](https://catalog.ngc.nvidia.com/) 