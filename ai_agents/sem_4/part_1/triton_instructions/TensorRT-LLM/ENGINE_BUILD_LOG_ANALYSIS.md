# Анализ логов сборки движка TensorRT-LLM


## 1. Инициализация и настройка плагинов

В начале лога выводится версия TensorRT-LLM и перечисляются настройки используемых плагинов. Эти плагины являются оптимизированными CUDA-ядрами для ключевых операций в трансформерных моделях.

**На что обратить внимание:**
- Версия TensorRT-LLM.
- Какие плагины (`gpt_attention_plugin`, `gemm_plugin` и т.д.) включены и с какими параметрами (например, `float16`).

```
[TensorRT-LLM] TensorRT-LLM version: 0.20.0
...
[07/20/2025-12:12:38] [TRT-LLM] [I] Set gpt_attention_plugin to float16.
[07/20/2025-12:12:38] [TRT-LLM] [I] Set gemm_plugin to float16.
...
[07/20/2025-12:12:38] [TRT-LLM] [I] Set remove_input_padding to True.
```

## 2. Определение параметров GPU

Далее система определяет и логирует характеристики графического процессора, на котором будет происходить сборка и запуск движка. Это важная информация для понимания производительности.

**На что обратить внимание:**
- Compute capability (в данном случае 8, 9).
- Количество SM-блоков, тактовая частота, объём и пропускная способность памяти.

```
[07/20/2025-12:12:38] [TRT-LLM] [I] Compute capability: (8, 9)
[07/20/2025-12:12:38] [TRT-LLM] [I] SM count: 34
[07/20/2025-12:12:38] [TRT-LLM] [I] SM clock: 3105 MHz
[07/20/2025-12:12:38] [TRT-LLM] [I] float16 TFLOPS: 54
[07/20/2025-12:12:38] [TRT-LLM] [I] Total Memory: 15 GiB
```

## 3. Построение сети

На этом этапе TensorRT-LLM конструирует вычислительный граф сети на основе предоставленной модели.

**На что обратить внимание:**
- Успешное завершение построения сети и время, затраченное на это.

```
[07/20/2025-12:12:50] [TRT-LLM] [I] Total time of constructing network from module object 11.116095542907715 seconds
```

## 4. Сборка и оптимизация движка

Это самый длительный и важный этап. TensorRT применяет различные оптимизации (fusions, layer eliminations) и подбирает наиболее быстрые ядра (kernels) для целевого GPU.

**На что обратить внимание:**
- Сообщения от `[TRT]`.
- Успешное завершение генерации движка (`Engine generation completed`).
- Пиковое потребление памяти в процессе сборки.

```
[07/20/2025-12:12:50] [TRT-LLM] [I] Build TensorRT engine Unnamed Network 0
...
[07/20/2025-12:13:02] [TRT] [I] Engine generation completed in 9.47165 seconds.
[07/20/2025-12:13:02] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 2891 MiB
[07/20/2025-12:13:04] [TRT-LLM] [I] Total time of building Unnamed Network 0: 00:00:14
```

## 5. Сериализация движка

После успешной сборки оптимизированный движок сохраняется в файл. Этот файл (`.engine`) будет использоваться сервером Triton для инференса.

**На что обратить внимание:**
- Путь, по которому сохраняется движок.
- Сообщение об успешной сериализации.

```
[07/20/2025-12:13:04] [TRT-LLM] [I] Serializing engine to /workspace/trt_engines/rank0.engine...
[07/20/2025-12:13:14] [TRT-LLM] [I] Engine serialized. Total time: 00:00:10
```

Успешное завершение всех этих этапов означает, что движок для вашей модели был успешно скомпилирован и готов к использованию. 